{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "import string\n",
    "\n",
    "from global_defs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1=torch.load('train_data_50_mut_1_c.pt')\n",
    "test_data_1=torch.load('test_data_50_mut_1_c.pt')\n",
    "train_labels_1=torch.load('train_labels_50_mut_1_c.pt')\n",
    "test_labels_1=torch.load('test_labels_50_mut_1_c.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_words=len(train_data_1)\n",
    "num_test_words=len(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_words=48042\n",
    "num_test_words=5338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recurrent_Layer(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Recurrent_Layer, self).__init__()\n",
    "        self.layer1 = nn.Embedding (vocab_size, hidden_size)\n",
    "        self.lstm=nn.LSTM( hidden_size, hidden_size, bidirectional=True)\n",
    "        self.fc=nn.Linear( 2* hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h_init,c_init):\n",
    "        g_seq          =self.layer1(x)\n",
    "        h_seq, (h_final, c_final) =self.lstm(g_seq, (h_init,c_init))\n",
    "        score_seq      =self.fc(h_seq)\n",
    "        \n",
    "        return score_seq,  h_final , c_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recurrent_Layer(\n",
      "  (layer1): Embedding(26, 256)\n",
      "  (lstm): LSTM(256, 256, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create the network\n",
    "hidden_size= 256\n",
    "vocab_size = 26\n",
    "batch_of_words = 1\n",
    "lstm_net = Recurrent_Layer(vocab_size,hidden_size).cuda()\n",
    "print(lstm_net)\n",
    "\n",
    "# send to device\n",
    "lstm_net = lstm_net.to(device)\n",
    "\n",
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define the learning rate\n",
    "my_lr = 0.05\n",
    "loss_plt=[]\n",
    "acc_plt=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utlitites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error( scores , labels ):\n",
    "\n",
    "    bs=scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches=indicator.sum()\n",
    "    corr=num_matches/len(predicted_labels)\n",
    "    return corr.item()\n",
    "\n",
    "def save_model_parameters():\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'lstm_model':lstm_net.state_dict(),\n",
    "                'lstm_optimizer': lstm_optimizer.state_dict(),\n",
    "                'train_loss': loss_plt, 'train_accuracy': accu_plt, \n",
    "                'test_loss': test_loss_plt,\n",
    "                'test_accuracy': accuracy_test_plt, 'confusion matrix_parameters':confusion_mtx_parameters}, 'LSTM+Biderctional.pt')\n",
    "\n",
    "#                 'incorrect_to_correct':confusion_param[0],  'correct_to_correct':confusion_param[2],\n",
    "#                 'correct_to_incorrect':confusion_param[1],'regenerate':confusion_param[3]\n",
    "               \n",
    "        \n",
    "def confusion_parameters(scores,target_tensor,inpute_tensor,conf_counter):\n",
    "\n",
    "    \n",
    "    if torch.all(torch.eq(target_tensor, scores.argmax(dim=1)))==1 and torch.all(torch.eq(inpute_tensor,target_tensor))==0: ### making incorrect->correct\n",
    "        conf_counter[0] +=1\n",
    "\n",
    "    if torch.all(torch.eq(inpute_tensor, scores.argmax(dim=1)))==0 and torch.all(torch.eq(inpute_tensor,target_tensor))==1: ### making correct->incorrect\n",
    "\n",
    "        conf_counter[1] +=1    \n",
    "\n",
    "\n",
    "    if torch.all(torch.eq(inpute_tensor, scores.argmax(dim=1)))==1 and torch.all(torch.eq(inpute_tensor,target_tensor))==1: ### making correct->correct\n",
    "\n",
    "        conf_counter[2] +=1                                                               \n",
    "\n",
    "    if torch.all(torch.eq(inpute_tensor, scores.argmax(dim=1)))==1 and torch.all(torch.eq(inpute_tensor,target_tensor))==0: ### making inccorrect->correct or regenerate the input \n",
    "\n",
    "        conf_counter[3] +=1  \n",
    "    return conf_counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "    \n",
    "    # to deactivate dropout regularization during testing\n",
    "    lstm_net.eval()\n",
    "    # initilizations \n",
    "    running_loss=0; num_batches=0;num_matches=0 ;acc_plt=[];loss_plt=[]\n",
    "    \n",
    "    # counts for computing correct and incorrect proportion\n",
    "    count=torch.zeros(4)\n",
    "    cnt_list=torch.zeros(4)\n",
    "    cnf_mtx_count=torch.zeros(4)\n",
    "\n",
    "    for i in range(0,num_test_words):\n",
    "        word_length = len(test_data_1 [i])\n",
    "        \n",
    "        # load data\n",
    "        inpute_tensor = test_data_1[i].cuda()\n",
    "        target_tensor = test_labels_1[i].cuda()\n",
    "        \n",
    "        # sending to GPU\n",
    "        inpute_tensor = inpute_tensor.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "        \n",
    "        h = torch.zeros(2,batch_of_words,  hidden_size).cuda()\n",
    "        c = torch.zeros(2,batch_of_words,  hidden_size).cuda()\n",
    "        h = h.to(device)\n",
    "        c = c.to(device)\n",
    "    \n",
    "        # forward pass\n",
    "        scores_char, h, c = lstm_net(inpute_tensor.view(word_length,1), h, c)\n",
    "        \n",
    "        # reshape before calculating the loss for easier slicing of mini batch of words\n",
    "        scores_char = scores_char.view(word_length*batch_of_words,vocab_size)\n",
    "        target_tensor = target_tensor.contiguous()\n",
    "        target_tensor = target_tensor.view(word_length*batch_of_words)\n",
    "        \n",
    "        # calculating the loss of batch of character sthat constrcut a words\n",
    "        loss_char = criterion(scores_char, target_tensor)# do we need to add the loss for every \n",
    "        \n",
    "        # accumalate the loss\n",
    "        running_loss += loss_char.item()\n",
    "        num_batches +=1 \n",
    "        \n",
    "        # computing accuracy\n",
    "        num_matches += get_error(scores_char, target_tensor)\n",
    "   \n",
    "   #=======================================================#\n",
    "        # compute confusion paramters for every word\n",
    "        cnf_mtx_count=confusion_parameters(scores_char,target_tensor,inpute_tensor,count)\n",
    "        #============================================# \n",
    "        \n",
    "\n",
    "    ###====Different Metrics for evaluation=============###\n",
    "    \n",
    "    # counter for computing confusion matrix\n",
    "#     cnt_list[0].append(cnf_mtx_count[0].item())\n",
    "#     cnt_list[1].append(cnf_mtx_count[1].item())    \n",
    "#     cnt_list[2].append(cnf_mtx_count[2].item())\n",
    "#     cnt_list[3].append(cnf_mtx_count[3].item())\n",
    "    \n",
    "    # accuracy and loss \n",
    "    accuracy= (num_matches/num_test_words)*100\n",
    "    acc_plt.append(accuracy)\n",
    "    total_loss = running_loss/num_batches \n",
    "    loss_plt.append(total_loss)\n",
    "    \n",
    "    # printing results \n",
    "    print('Test==: loss = ',(total_loss),'\\t accuracy=', accuracy,'%' )\n",
    "    return acc_plt, loss_plt, cnf_mtx_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test==: loss =  0.1131328574592399 \t accuracy= 83.94529786436867 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([83.94529786436867],\n",
       " [0.1131328574592399],\n",
       " [[2235.0], [18.0], [2246.0], [387.0], []])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_on_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train::: epoch= 1 \t lr= 0.05 \t (loss)= 0.1683590938748826 \t (accuracy)= 68.53378293992756 % \t time= 242.80848741531372\n",
      "Test==: loss =  1.5605131608783551 \t accuracy= 2.0232296740352194 %\n",
      "\n",
      "Train::: epoch= 2 \t lr= 0.05 \t (loss)= 0.1037016541074899 \t (accuracy)= 79.80933349985429 % \t time= 507.6129548549652\n",
      "Test==: loss =  1.4938455778578927 \t accuracy= 2.9973772948669914 %\n",
      "\n",
      "Train::: epoch= 3 \t lr= 0.05 \t (loss)= 0.08805007854499278 \t (accuracy)= 82.64227134590567 % \t time= 771.8383738994598\n",
      "Test==: loss =  1.474786675305714 \t accuracy= 2.941176470588235 %\n",
      "\n",
      "Train::: epoch= 4 \t lr= 0.05 \t (loss)= 0.07622907352850429 \t (accuracy)= 84.53020273926981 % \t time= 1037.368916273117\n",
      "Test==: loss =  1.3896928452788229 \t accuracy= 4.571000374672162 %\n",
      "\n",
      "Train::: epoch= 5 \t lr= 0.05 \t (loss)= 0.06900725877822109 \t (accuracy)= 85.77702843345406 % \t time= 1301.1735048294067\n",
      "Test==: loss =  1.2630484622501672 \t accuracy= 5.488947171225178 %\n",
      "\n",
      "Train::: epoch= 6 \t lr= 0.05 \t (loss)= 0.061162211288743724 \t (accuracy)= 86.90937096707047 % \t time= 1564.4426367282867\n",
      "Test==: loss =  1.2538027570012868 \t accuracy= 6.575496440614462 %\n",
      "\n",
      "Train::: epoch= 7 \t lr= 0.05 \t (loss)= 0.054880219571068735 \t (accuracy)= 88.02506140460432 % \t time= 1828.09335398674\n",
      "Test==: loss =  1.142816657691176 \t accuracy= 8.055451479955039 %\n",
      "\n",
      "Train::: epoch= 8 \t lr= 0.05 \t (loss)= 0.04870460097558618 \t (accuracy)= 89.0345947296116 % \t time= 2092.153125524521\n",
      "Test==: loss =  1.068172784742916 \t accuracy= 9.666541775946047 %\n",
      "\n",
      "Train::: epoch= 9 \t lr= 0.05 \t (loss)= 0.04383960098001815 \t (accuracy)= 90.00874235044336 % \t time= 2357.0281522274017\n",
      "Test==: loss =  1.1295420343585583 \t accuracy= 10.35968527538404 %\n",
      "\n",
      "Train::: epoch= 10 \t lr= 0.045454545454545456 \t (loss)= 0.03890237600675171 \t (accuracy)= 90.96623787519253 % \t time= 2620.0640721321106\n",
      "Test==: loss =  1.0028186737928544 \t accuracy= 13.675533907830648 %\n",
      "\n",
      "Train::: epoch= 11 \t lr= 0.045454545454545456 \t (loss)= 0.034111520673814386 \t (accuracy)= 92.02364597643728 % \t time= 2886.0156869888306\n",
      "Test==: loss =  0.9628598042893923 \t accuracy= 15.998501311352568 %\n",
      "\n",
      "Train::: epoch= 12 \t lr= 0.045454545454545456 \t (loss)= 0.030502175075851283 \t (accuracy)= 92.78756088422631 % \t time= 3149.7915530204773\n",
      "Test==: loss =  0.907223049786303 \t accuracy= 16.616710378418883 %\n",
      "\n",
      "Train::: epoch= 13 \t lr= 0.045454545454545456 \t (loss)= 0.027805722033994833 \t (accuracy)= 93.37038424711712 % \t time= 3414.698956012726\n",
      "Test==: loss =  0.9426458930510028 \t accuracy= 16.878980891719745 %\n",
      "\n",
      "Train::: epoch= 14 \t lr= 0.045454545454545456 \t (loss)= 0.025045348471718843 \t (accuracy)= 93.94696307397695 % \t time= 3678.6103405952454\n",
      "Test==: loss =  0.8616215294100139 \t accuracy= 21.41251405020607 %\n",
      "\n",
      "Train::: epoch= 15 \t lr= 0.045454545454545456 \t (loss)= 0.022654411990007776 \t (accuracy)= 94.5859872611465 % \t time= 3942.2931180000305\n",
      "Test==: loss =  0.8706619896623929 \t accuracy= 19.67028849756463 %\n",
      "\n",
      "Train::: epoch= 16 \t lr= 0.045454545454545456 \t (loss)= 0.02053913326140823 \t (accuracy)= 95.15632155197535 % \t time= 4206.94108247757\n",
      "Test==: loss =  0.8316113051766236 \t accuracy= 23.473210940427126 %\n",
      "\n",
      "Train::: epoch= 17 \t lr= 0.045454545454545456 \t (loss)= 0.018844465323580518 \t (accuracy)= 95.58719453811248 % \t time= 4471.32150220871\n",
      "Test==: loss =  0.8127707837386423 \t accuracy= 24.185088047958036 %\n",
      "\n",
      "Train::: epoch= 18 \t lr= 0.045454545454545456 \t (loss)= 0.0179013529700857 \t (accuracy)= 95.84946505141335 % \t time= 4736.859488964081\n",
      "Test==: loss =  0.8008365215846112 \t accuracy= 25.40277257399775 %\n",
      "\n",
      "Train::: epoch= 19 \t lr= 0.045454545454545456 \t (loss)= 0.01626746423534646 \t (accuracy)= 96.3511094459015 % \t time= 5003.298118591309\n",
      "Test==: loss =  0.8191307935607669 \t accuracy= 25.009366804046458 %\n",
      "\n",
      "Train::: epoch= 20 \t lr= 0.04132231404958678 \t (loss)= 0.015119071938343732 \t (accuracy)= 96.67998834353274 % \t time= 5268.655380010605\n",
      "Test==: loss =  0.7224103064786506 \t accuracy= 28.512551517422256 %\n",
      "\n",
      "Train::: epoch= 21 \t lr= 0.04132231404958678 \t (loss)= 0.013234996664766876 \t (accuracy)= 97.32733857874359 % \t time= 5534.366240501404\n",
      "Test==: loss =  0.7575867279132592 \t accuracy= 27.575871112776323 %\n",
      "\n",
      "Train::: epoch= 22 \t lr= 0.04132231404958678 \t (loss)= 0.012400199198547242 \t (accuracy)= 97.61250572415803 % \t time= 5800.383747816086\n",
      "Test==: loss =  0.7585053015128304 \t accuracy= 27.575871112776323 %\n",
      "\n",
      "Train::: epoch= 23 \t lr= 0.04132231404958678 \t (loss)= 0.011425720459787384 \t (accuracy)= 97.81024936513883 % \t time= 6066.035429239273\n",
      "Test==: loss =  0.6657779675857378 \t accuracy= 32.18433870363432 %\n",
      "\n",
      "Train::: epoch= 24 \t lr= 0.04132231404958678 \t (loss)= 0.010569484976974552 \t (accuracy)= 98.09125348653261 % \t time= 6334.008816957474\n",
      "Test==: loss =  0.6776749340928573 \t accuracy= 31.659797677032596 %\n",
      "\n",
      "Train::: epoch= 25 \t lr= 0.04132231404958678 \t (loss)= 0.009781175115918826 \t (accuracy)= 98.28275259148245 % \t time= 6600.258982419968\n",
      "Test==: loss =  0.7010370158203126 \t accuracy= 30.7605844885725 %\n",
      "\n",
      "Train::: epoch= 26 \t lr= 0.04132231404958678 \t (loss)= 0.009249821045423535 \t (accuracy)= 98.48049623246327 % \t time= 6865.834060668945\n",
      "Test==: loss =  0.6298793029168727 \t accuracy= 34.03896590483327 %\n",
      "\n",
      "Train::: epoch= 27 \t lr= 0.04132231404958678 \t (loss)= 0.008541887113932547 \t (accuracy)= 98.77607093792932 % \t time= 7132.122805356979\n",
      "Test==: loss =  0.6522719360628922 \t accuracy= 34.319970026227054 %\n",
      "\n",
      "Train::: epoch= 28 \t lr= 0.04132231404958678 \t (loss)= 0.008096008095195853 \t (accuracy)= 98.85724990633196 % \t time= 7398.1220054626465\n",
      "Test==: loss =  0.6345241453927577 \t accuracy= 35.79992506556763 %\n",
      "\n",
      "Train::: epoch= 29 \t lr= 0.04132231404958678 \t (loss)= 0.0074050996756065985 \t (accuracy)= 98.98005911494108 % \t time= 7664.831914901733\n",
      "Test==: loss =  0.6558632415226251 \t accuracy= 34.582240539527916 %\n",
      "\n",
      "Train::: epoch= 30 \t lr= 0.037565740045078885 \t (loss)= 0.007012540197271486 \t (accuracy)= 99.13617251571542 % \t time= 7930.326420068741\n",
      "Test==: loss =  0.5903584827437137 \t accuracy= 37.31734732109404 %\n",
      "\n",
      "Train::: epoch= 31 \t lr= 0.037565740045078885 \t (loss)= 0.006658950837594858 \t (accuracy)= 99.20694392406644 % \t time= 8196.645896434784\n",
      "Test==: loss =  0.6155045716401977 \t accuracy= 36.717871862120646 %\n",
      "\n",
      "Train::: epoch= 32 \t lr= 0.037565740045078885 \t (loss)= 0.006161610286084354 \t (accuracy)= 99.32559010865492 % \t time= 8467.644261837006\n",
      "Test==: loss =  0.5925476303010372 \t accuracy= 38.29149494192581 %\n",
      "\n",
      "Train::: epoch= 33 \t lr= 0.037565740045078885 \t (loss)= 0.006050487097922394 \t (accuracy)= 99.36930186087174 % \t time= 8730.531582832336\n",
      "Test==: loss =  0.5636299935075049 \t accuracy= 40.35219183214687 %\n",
      "\n",
      "Train::: epoch= 34 \t lr= 0.037565740045078885 \t (loss)= 0.005848658707947609 \t (accuracy)= 99.40468756504724 % \t time= 8992.254598855972\n",
      "Test==: loss =  0.537492144768588 \t accuracy= 42.35668789808918 %\n",
      "\n",
      "Train::: epoch= 35 \t lr= 0.037565740045078885 \t (loss)= 0.005522753510456429 \t (accuracy)= 99.47962199741892 % \t time= 9254.945772647858\n",
      "Test==: loss =  0.5137517936445024 \t accuracy= 43.87411015361559 %\n",
      "\n",
      "Train::: epoch= 36 \t lr= 0.037565740045078885 \t (loss)= 0.005199288892171729 \t (accuracy)= 99.51292618958412 % \t time= 9515.674215316772\n",
      "Test==: loss =  0.5157290241044368 \t accuracy= 44.023979018358936 %\n",
      "\n",
      "Train::: epoch= 37 \t lr= 0.037565740045078885 \t (loss)= 0.004940799568334015 \t (accuracy)= 99.55247491778027 % \t time= 9776.48874282837\n",
      "Test==: loss =  0.49458471585605807 \t accuracy= 46.10340951667291 %\n",
      "\n",
      "Train::: epoch= 38 \t lr= 0.037565740045078885 \t (loss)= 0.004818139063591032 \t (accuracy)= 99.5462303817493 % \t time= 10036.946554422379\n",
      "Test==: loss =  0.4939737930976906 \t accuracy= 46.12214312476583 %\n",
      "\n",
      "Train::: epoch= 39 \t lr= 0.037565740045078885 \t (loss)= 0.0047523735567410776 \t (accuracy)= 99.56912701386287 % \t time= 10298.871235132217\n",
      "Test==: loss =  0.46549135855027596 \t accuracy= 48.53877856875234 %\n",
      "\n",
      "Train::: epoch= 40 \t lr= 0.03415067276825353 \t (loss)= 0.004606471038925694 \t (accuracy)= 99.57120852587319 % \t time= 10559.976239681244\n",
      "Test==: loss =  0.4589185918647917 \t accuracy= 49.15698763581866 %\n",
      "\n",
      "Train::: epoch= 41 \t lr= 0.03415067276825353 \t (loss)= 0.004430923681591233 \t (accuracy)= 99.5878606219558 % \t time= 10820.511749744415\n",
      "Test==: loss =  0.4410613969515147 \t accuracy= 50.599475458973394 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train::: epoch= 42 \t lr= 0.03415067276825353 \t (loss)= 0.004241817885135002 \t (accuracy)= 99.60867574205903 % \t time= 11080.738979816437\n",
      "Test==: loss =  0.41917407474071233 \t accuracy= 52.285500187336076 %\n",
      "\n",
      "Train::: epoch= 43 \t lr= 0.03415067276825353 \t (loss)= 0.0041051044837509916 \t (accuracy)= 99.62116481412097 % \t time= 11340.830182313919\n",
      "Test==: loss =  0.40457955193662504 \t accuracy= 53.259647808167855 %\n",
      "\n",
      "Train::: epoch= 44 \t lr= 0.03415067276825353 \t (loss)= 0.004113597120300827 \t (accuracy)= 99.60867574205903 % \t time= 11601.667145967484\n",
      "Test==: loss =  0.38084777773378076 \t accuracy= 55.226676657924315 %\n",
      "\n",
      "Train::: epoch= 45 \t lr= 0.03415067276825353 \t (loss)= 0.004185127791977157 \t (accuracy)= 99.59826818200742 % \t time= 11865.776890993118\n",
      "Test==: loss =  0.3734520086096365 \t accuracy= 55.86361933308355 %\n",
      "\n",
      "Train::: epoch= 46 \t lr= 0.03415067276825353 \t (loss)= 0.00414937082921051 \t (accuracy)= 99.60034969401774 % \t time= 12128.36697268486\n",
      "Test==: loss =  0.36064012315739113 \t accuracy= 56.8190333458224 %\n",
      "\n",
      "Train::: epoch= 47 \t lr= 0.03415067276825353 \t (loss)= 0.00402821626670905 \t (accuracy)= 99.60243120602806 % \t time= 12391.091785669327\n",
      "Test==: loss =  0.3563889663062834 \t accuracy= 57.21243911577369 %\n",
      "\n",
      "Train::: epoch= 48 \t lr= 0.03415067276825353 \t (loss)= 0.003926119077608856 \t (accuracy)= 99.59826818200742 % \t time= 12653.465809106827\n",
      "Test==: loss =  0.34258276153109773 \t accuracy= 58.954664668415134 %\n",
      "\n",
      "Train::: epoch= 49 \t lr= 0.03415067276825353 \t (loss)= 0.003966710050850832 \t (accuracy)= 99.61283876607968 % \t time= 12917.95629310608\n",
      "Test==: loss =  0.335412381785743 \t accuracy= 59.74147620831772 %\n",
      "\n",
      "Train::: epoch= 50 \t lr= 0.03104606615295775 \t (loss)= 0.0038340914559519272 \t (accuracy)= 99.61075725406936 % \t time= 13179.791589260101\n",
      "Test==: loss =  0.3323336470565654 \t accuracy= 59.49793930310978 %\n",
      "\n",
      "Train::: epoch= 51 \t lr= 0.03104606615295775 \t (loss)= 0.003726752016545009 \t (accuracy)= 99.61492027809 % \t time= 13446.050685882568\n",
      "Test==: loss =  0.3266184966213777 \t accuracy= 60.6219557886849 %\n",
      "\n",
      "Train::: epoch= 52 \t lr= 0.03104606615295775 \t (loss)= 0.0037573171878988692 \t (accuracy)= 99.61700179010032 % \t time= 13710.43270111084\n",
      "Test==: loss =  0.3216251015930518 \t accuracy= 61.146496815286625 %\n",
      "\n",
      "Train::: epoch= 53 \t lr= 0.03104606615295775 \t (loss)= 0.0038006065204798712 \t (accuracy)= 99.60451271803838 % \t time= 13972.82461977005\n",
      "Test==: loss =  0.3231911074769231 \t accuracy= 61.31509928812289 %\n",
      "\n",
      "Train::: epoch= 54 \t lr= 0.03104606615295775 \t (loss)= 0.003743101563477277 \t (accuracy)= 99.58369759793514 % \t time= 14236.114716291428\n",
      "Test==: loss =  0.320665765605137 \t accuracy= 61.78343949044586 %\n",
      "\n",
      "Train::: epoch= 55 \t lr= 0.03104606615295775 \t (loss)= 0.00407686985612773 \t (accuracy)= 99.54414886973898 % \t time= 14500.928983926773\n",
      "Test==: loss =  0.32142888707525535 \t accuracy= 61.55863619333084 %\n",
      "\n",
      "Train::: epoch= 56 \t lr= 0.03104606615295775 \t (loss)= 0.004000595077082922 \t (accuracy)= 99.54414886973898 % \t time= 14767.255442142487\n",
      "Test==: loss =  0.31477301855023915 \t accuracy= 62.00824278756089 %\n",
      "\n",
      "Train::: epoch= 57 \t lr= 0.03104606615295775 \t (loss)= 0.003825092088057007 \t (accuracy)= 99.56496398984223 % \t time= 15032.193281173706\n",
      "Test==: loss =  0.3140413913144373 \t accuracy= 62.21431247658299 %\n",
      "\n",
      "Train::: epoch= 58 \t lr= 0.03104606615295775 \t (loss)= 0.0037684695655736686 \t (accuracy)= 99.56080096582157 % \t time= 15296.19547700882\n",
      "Test==: loss =  0.29837259438311725 \t accuracy= 63.9378044211315 %\n",
      "\n",
      "Train::: epoch= 59 \t lr= 0.03104606615295775 \t (loss)= 0.0037143474331686817 \t (accuracy)= 99.5961866699971 % \t time= 15560.240392923355\n",
      "Test==: loss =  0.29121599878251125 \t accuracy= 64.61221431247658 %\n",
      "\n",
      "Train::: epoch= 60 \t lr= 0.028223696502688862 \t (loss)= 0.003572869385103352 \t (accuracy)= 99.60034969401774 % \t time= 15823.144181728363\n",
      "Test==: loss =  0.2748290904626886 \t accuracy= 66.22330460846759 %\n",
      "\n",
      "Train::: epoch= 61 \t lr= 0.028223696502688862 \t (loss)= 0.0035047979513024912 \t (accuracy)= 99.61700179010032 % \t time= 16086.087762117386\n",
      "Test==: loss =  0.2617217084461574 \t accuracy= 67.36605470213564 %\n",
      "\n",
      "Train::: epoch= 62 \t lr= 0.028223696502688862 \t (loss)= 0.003546610269718903 \t (accuracy)= 99.57329003788352 % \t time= 16349.019909143448\n",
      "Test==: loss =  0.2576714984682495 \t accuracy= 67.66579243162234 %\n",
      "\n",
      "Train::: epoch= 63 \t lr= 0.028223696502688862 \t (loss)= 0.0034834186740350893 \t (accuracy)= 99.60243120602806 % \t time= 16612.375326395035\n",
      "Test==: loss =  0.25346628886633876 \t accuracy= 68.28400149868865 %\n",
      "\n",
      "Train::: epoch= 64 \t lr= 0.028223696502688862 \t (loss)= 0.0035287596348788962 \t (accuracy)= 99.58161608592482 % \t time= 16876.957403182983\n",
      "Test==: loss =  0.25045846215337747 \t accuracy= 68.63994005245411 %\n",
      "\n",
      "Train::: epoch= 65 \t lr= 0.028223696502688862 \t (loss)= 0.0033895932283154176 \t (accuracy)= 99.61283876607968 % \t time= 17141.47190594673\n",
      "Test==: loss =  0.24200700949739157 \t accuracy= 69.52041963282129 %\n",
      "\n",
      "Train::: epoch= 66 \t lr= 0.028223696502688862 \t (loss)= 0.0033112331548637757 \t (accuracy)= 99.61075725406936 % \t time= 17404.14741420746\n",
      "Test==: loss =  0.23766173945946778 \t accuracy= 70.17609591607344 %\n",
      "\n",
      "Train::: epoch= 67 \t lr= 0.028223696502688862 \t (loss)= 0.0032623808947787086 \t (accuracy)= 99.60867574205903 % \t time= 17667.30246400833\n",
      "Test==: loss =  0.231686175287555 \t accuracy= 70.77557137504684 %\n",
      "\n",
      "Train::: epoch= 68 \t lr= 0.028223696502688862 \t (loss)= 0.0033123508093350212 \t (accuracy)= 99.58994213396612 % \t time= 17929.095291614532\n",
      "Test==: loss =  0.23323566401618834 \t accuracy= 70.47583364556014 %\n",
      "\n",
      "Train::: epoch= 69 \t lr= 0.028223696502688862 \t (loss)= 0.003257496539443133 \t (accuracy)= 99.60243120602806 % \t time= 18192.209968805313\n",
      "Test==: loss =  0.22625981514291393 \t accuracy= 71.56238291494942 %\n",
      "\n",
      "Train::: epoch= 70 \t lr= 0.025657905911535328 \t (loss)= 0.0032373013885244003 \t (accuracy)= 99.59202364597644 % \t time= 18455.45156431198\n",
      "Test==: loss =  0.2198916465759185 \t accuracy= 72.25552641438742 %\n",
      "\n",
      "Train::: epoch= 71 \t lr= 0.025657905911535328 \t (loss)= 0.003144970777259056 \t (accuracy)= 99.60451271803838 % \t time= 18718.563572883606\n",
      "Test==: loss =  0.2148068260797488 \t accuracy= 72.85500187336082 %\n",
      "\n",
      "Train::: epoch= 72 \t lr= 0.025657905911535328 \t (loss)= 0.0031757005492681852 \t (accuracy)= 99.59410515798676 % \t time= 18983.061289072037\n",
      "Test==: loss =  0.21129491927372676 \t accuracy= 73.43574372424129 %\n",
      "\n",
      "Train::: epoch= 73 \t lr= 0.025657905911535328 \t (loss)= 0.0031484127097351883 \t (accuracy)= 99.58369759793514 % \t time= 19246.089787483215\n",
      "Test==: loss =  0.20624434822117768 \t accuracy= 74.12888722367929 %\n",
      "\n",
      "Train::: epoch= 74 \t lr= 0.025657905911535328 \t (loss)= 0.0033642865385312593 \t (accuracy)= 99.55039340576995 % \t time= 19508.40953350067\n",
      "Test==: loss =  0.2060371317489563 \t accuracy= 73.84788310228551 %\n",
      "\n",
      "Train::: epoch= 75 \t lr= 0.025657905911535328 \t (loss)= 0.0032068414835563284 \t (accuracy)= 99.57120852587319 % \t time= 19771.40089416504\n",
      "Test==: loss =  0.1995266668365808 \t accuracy= 74.42862495316598 %\n",
      "\n",
      "Train::: epoch= 76 \t lr= 0.025657905911535328 \t (loss)= 0.003087221578122673 \t (accuracy)= 99.58161608592482 % \t time= 20033.24420619011\n",
      "Test==: loss =  0.19571651953410316 \t accuracy= 75.38403896590484 %\n",
      "\n",
      "Train::: epoch= 77 \t lr= 0.025657905911535328 \t (loss)= 0.002984203704443195 \t (accuracy)= 99.60243120602806 % \t time= 20296.035839796066\n",
      "Test==: loss =  0.1924797072373148 \t accuracy= 75.77744473585612 %\n",
      "\n",
      "Train::: epoch= 78 \t lr= 0.025657905911535328 \t (loss)= 0.0029648431954914004 \t (accuracy)= 99.60243120602806 % \t time= 20558.980654239655\n",
      "Test==: loss =  0.18896617704097263 \t accuracy= 75.87111277632071 %\n",
      "\n",
      "Train::: epoch= 79 \t lr= 0.025657905911535328 \t (loss)= 0.0029620473632554364 \t (accuracy)= 99.60034969401774 % \t time= 20821.15034031868\n",
      "Test==: loss =  0.18535627835410964 \t accuracy= 76.00224803297115 %\n",
      "\n",
      "Train::: epoch= 80 \t lr= 0.02332536901048666 \t (loss)= 0.0028532727161491565 \t (accuracy)= 99.60451271803838 % \t time= 21082.822162389755\n",
      "Test==: loss =  0.18035767172424375 \t accuracy= 76.39565380292245 %\n",
      "\n",
      "Train::: epoch= 81 \t lr= 0.02332536901048666 \t (loss)= 0.0028420506490943456 \t (accuracy)= 99.59202364597644 % \t time= 21344.021825790405\n",
      "Test==: loss =  0.17772715119974672 \t accuracy= 76.95766204571001 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train::: epoch= 82 \t lr= 0.02332536901048666 \t (loss)= 0.0028763645252432558 \t (accuracy)= 99.58369759793514 % \t time= 21605.56140947342\n",
      "Test==: loss =  0.1768150907093711 \t accuracy= 76.82652678905957 %\n",
      "\n",
      "Train::: epoch= 83 \t lr= 0.02332536901048666 \t (loss)= 0.0029180383626455 \t (accuracy)= 99.56496398984223 % \t time= 21868.939032554626\n",
      "Test==: loss =  0.18047267203602926 \t accuracy= 76.17085050580742 %\n",
      "\n",
      "Train::: epoch= 84 \t lr= 0.02332536901048666 \t (loss)= 0.003169403350389399 \t (accuracy)= 99.53374130968736 % \t time= 22129.991582155228\n",
      "Test==: loss =  0.17986105850077294 \t accuracy= 76.6579243162233 %\n",
      "\n",
      "Train::: epoch= 85 \t lr= 0.02332536901048666 \t (loss)= 0.0029381332696562573 \t (accuracy)= 99.56496398984223 % \t time= 22395.70442533493\n",
      "Test==: loss =  0.1750762851679036 \t accuracy= 76.8639940052454 %\n",
      "\n",
      "Train::: epoch= 86 \t lr= 0.02332536901048666 \t (loss)= 0.0028798215005314265 \t (accuracy)= 99.57745306190417 % \t time= 22658.59889125824\n",
      "Test==: loss =  0.17367555268382406 \t accuracy= 77.20119895091796 %\n",
      "\n",
      "Train::: epoch= 87 \t lr= 0.02332536901048666 \t (loss)= 0.0028668808982002555 \t (accuracy)= 99.57120852587319 % \t time= 22920.671562194824\n",
      "Test==: loss =  0.1729546400871324 \t accuracy= 77.18246534282503 %\n",
      "\n",
      "Train::: epoch= 88 \t lr= 0.02332536901048666 \t (loss)= 0.002824194244096468 \t (accuracy)= 99.57537154989384 % \t time= 23181.799434185028\n",
      "Test==: loss =  0.17093772385256203 \t accuracy= 77.42600224803297 %\n",
      "\n",
      "Train::: epoch= 89 \t lr= 0.02332536901048666 \t (loss)= 0.002950505866307587 \t (accuracy)= 99.5795345739145 % \t time= 23443.206300258636\n",
      "Test==: loss =  0.1680703502323694 \t accuracy= 77.74447358561258 %\n",
      "\n",
      "Train::: epoch= 90 \t lr= 0.021204880918624235 \t (loss)= 0.00286278577049189 \t (accuracy)= 99.57745306190417 % \t time= 23705.498314380646\n",
      "Test==: loss =  0.16744232051706964 \t accuracy= 77.87560884226302 %\n",
      "\n",
      "Train::: epoch= 91 \t lr= 0.021204880918624235 \t (loss)= 0.0029122131344820404 \t (accuracy)= 99.56912701386287 % \t time= 23967.66582942009\n",
      "Test==: loss =  0.16600090607619514 \t accuracy= 77.76320719370551 %\n",
      "\n",
      "Train::: epoch= 92 \t lr= 0.021204880918624235 \t (loss)= 0.002915328873389399 \t (accuracy)= 99.57120852587319 % \t time= 24229.33679676056\n",
      "Test==: loss =  0.16316585224612815 \t accuracy= 78.10041213937804 %\n",
      "\n",
      "Train::: epoch= 93 \t lr= 0.021204880918624235 \t (loss)= 0.002985699692781509 \t (accuracy)= 99.54831189375962 % \t time= 24490.031282186508\n",
      "Test==: loss =  0.1624249730585353 \t accuracy= 78.30648182840015 %\n",
      "\n",
      "Train::: epoch= 94 \t lr= 0.021204880918624235 \t (loss)= 0.0029990457918708207 \t (accuracy)= 99.56704550185255 % \t time= 24752.28981280327\n",
      "Test==: loss =  0.16060264863889168 \t accuracy= 78.53128512551517 %\n",
      "\n",
      "Train::: epoch= 95 \t lr= 0.021204880918624235 \t (loss)= 0.0029450102904669557 \t (accuracy)= 99.5462303817493 % \t time= 25013.124631881714\n",
      "Test==: loss =  0.16146322751092534 \t accuracy= 78.32521543649307 %\n",
      "\n",
      "Train::: epoch= 96 \t lr= 0.021204880918624235 \t (loss)= 0.0028810027644296512 \t (accuracy)= 99.56704550185255 % \t time= 25273.804797887802\n",
      "Test==: loss =  0.15892716968373088 \t accuracy= 79.01835893593106 %\n",
      "\n",
      "Train::: epoch= 97 \t lr= 0.021204880918624235 \t (loss)= 0.002886892503552819 \t (accuracy)= 99.57745306190417 % \t time= 25535.313080072403\n",
      "Test==: loss =  0.15861535213984307 \t accuracy= 78.58748594979393 %\n",
      "\n",
      "Train::: epoch= 98 \t lr= 0.021204880918624235 \t (loss)= 0.0028827002419701854 \t (accuracy)= 99.56912701386287 % \t time= 25796.43987417221\n",
      "Test==: loss =  0.15626976109206012 \t accuracy= 79.01835893593106 %\n",
      "\n",
      "Train::: epoch= 99 \t lr= 0.021204880918624235 \t (loss)= 0.0028542988322866054 \t (accuracy)= 99.57329003788352 % \t time= 26058.94780611992\n",
      "Test==: loss =  0.15528370235802091 \t accuracy= 79.33683027351069 %\n",
      "\n",
      "Train::: epoch= 100 \t lr= 0.019277164471476576 \t (loss)= 0.002758886084823453 \t (accuracy)= 99.56080096582157 % \t time= 26321.316833734512\n",
      "Test==: loss =  0.15204247382294514 \t accuracy= 79.69276882727613 %\n",
      "\n",
      "Train::: epoch= 101 \t lr= 0.019277164471476576 \t (loss)= 0.002814973071253196 \t (accuracy)= 99.55871945381125 % \t time= 26587.62203645706\n",
      "Test==: loss =  0.15207995291271678 \t accuracy= 79.80517047583365 %\n",
      "\n",
      "Train::: epoch= 102 \t lr= 0.019277164471476576 \t (loss)= 0.0027575553193639694 \t (accuracy)= 99.56288247783189 % \t time= 26851.544110059738\n",
      "Test==: loss =  0.14986571045292424 \t accuracy= 79.99250655676283 %\n",
      "\n",
      "Train::: epoch= 103 \t lr= 0.019277164471476576 \t (loss)= 0.0026990858843552886 \t (accuracy)= 99.55663794180093 % \t time= 27115.879093647003\n",
      "Test==: loss =  0.14941243929869635 \t accuracy= 79.95503934057699 %\n",
      "\n",
      "Train::: epoch= 104 \t lr= 0.019277164471476576 \t (loss)= 0.00274479521028514 \t (accuracy)= 99.55039340576995 % \t time= 27380.629885196686\n",
      "Test==: loss =  0.14865720133666574 \t accuracy= 80.17984263769202 %\n",
      "\n",
      "Train::: epoch= 105 \t lr= 0.019277164471476576 \t (loss)= 0.002744646453286845 \t (accuracy)= 99.5462303817493 % \t time= 27646.430126428604\n",
      "Test==: loss =  0.1464388245285547 \t accuracy= 80.57324840764332 %\n",
      "\n",
      "Train::: epoch= 106 \t lr= 0.019277164471476576 \t (loss)= 0.0027895248336438916 \t (accuracy)= 99.54831189375962 % \t time= 27910.799643993378\n",
      "Test==: loss =  0.1455077401073905 \t accuracy= 80.66691644810791 %\n",
      "\n",
      "Train::: epoch= 107 \t lr= 0.019277164471476576 \t (loss)= 0.0027360021179450036 \t (accuracy)= 99.55247491778027 % \t time= 28174.861016511917\n",
      "Test==: loss =  0.1443108538144663 \t accuracy= 81.00412139378044 %\n",
      "\n",
      "Train::: epoch= 108 \t lr= 0.019277164471476576 \t (loss)= 0.0026988261535218095 \t (accuracy)= 99.55039340576995 % \t time= 28441.191799402237\n",
      "Test==: loss =  0.14271971279633963 \t accuracy= 81.21019108280255 %\n",
      "\n",
      "Train::: epoch= 109 \t lr= 0.019277164471476576 \t (loss)= 0.00264625520553835 \t (accuracy)= 99.56080096582157 % \t time= 28706.25323987007\n",
      "Test==: loss =  0.1419161989104385 \t accuracy= 81.15399025852379 %\n",
      "\n",
      "Train::: epoch= 110 \t lr= 0.017524694974069614 \t (loss)= 0.0026005543191908657 \t (accuracy)= 99.55871945381125 % \t time= 28973.324824810028\n",
      "Test==: loss =  0.1407423510543953 \t accuracy= 81.2663919070813 %\n",
      "\n",
      "Train::: epoch= 111 \t lr= 0.017524694974069614 \t (loss)= 0.002564003393942921 \t (accuracy)= 99.55247491778027 % \t time= 29239.09418964386\n",
      "Test==: loss =  0.14034171720727712 \t accuracy= 81.39752716373174 %\n",
      "\n",
      "Train::: epoch= 112 \t lr= 0.017524694974069614 \t (loss)= 0.0025955709298814485 \t (accuracy)= 99.55663794180093 % \t time= 29505.272927999496\n",
      "Test==: loss =  0.1402810381702172 \t accuracy= 81.41626077182465 %\n",
      "\n",
      "Train::: epoch= 113 \t lr= 0.017524694974069614 \t (loss)= 0.002584430751858535 \t (accuracy)= 99.54831189375962 % \t time= 29770.871292591095\n",
      "Test==: loss =  0.13932822914768622 \t accuracy= 81.79093293368302 %\n",
      "\n",
      "Train::: epoch= 114 \t lr= 0.017524694974069614 \t (loss)= 0.002595730700114121 \t (accuracy)= 99.5462303817493 % \t time= 30036.429688215256\n",
      "Test==: loss =  0.14018371946815977 \t accuracy= 81.49119520419633 %\n",
      "\n",
      "Train::: epoch= 115 \t lr= 0.017524694974069614 \t (loss)= 0.0027164762943242098 \t (accuracy)= 99.5295782856667 % \t time= 30301.144855499268\n",
      "Test==: loss =  0.13792731525594115 \t accuracy= 81.54739602847508 %\n",
      "\n",
      "Train::: epoch= 116 \t lr= 0.017524694974069614 \t (loss)= 0.002624677284542805 \t (accuracy)= 99.54206735772865 % \t time= 30564.929307222366\n",
      "Test==: loss =  0.13661165208924134 \t accuracy= 81.80966654177595 %\n",
      "\n",
      "Train::: epoch= 117 \t lr= 0.017524694974069614 \t (loss)= 0.0025785643039142967 \t (accuracy)= 99.54206735772865 % \t time= 30830.388511419296\n",
      "Test==: loss =  0.1364676248084574 \t accuracy= 81.82840014986887 %\n",
      "\n",
      "Train::: epoch= 118 \t lr= 0.017524694974069614 \t (loss)= 0.0025862418959850964 \t (accuracy)= 99.5295782856667 % \t time= 31095.249292373657\n",
      "Test==: loss =  0.13611156862395296 \t accuracy= 81.80966654177595 %\n",
      "\n",
      "Train::: epoch= 119 \t lr= 0.017524694974069614 \t (loss)= 0.002617647727071562 \t (accuracy)= 99.53165979767704 % \t time= 31360.209666252136\n",
      "Test==: loss =  0.13502641242490665 \t accuracy= 81.97826901461221 %\n",
      "\n",
      "Train::: epoch= 120 \t lr= 0.01593154088551783 \t (loss)= 0.002565333409479745 \t (accuracy)= 99.54831189375962 % \t time= 31624.60221004486\n",
      "Test==: loss =  0.1337463053381541 \t accuracy= 82.0719370550768 %\n",
      "\n",
      "Train::: epoch= 121 \t lr= 0.01593154088551783 \t (loss)= 0.002475574384678312 \t (accuracy)= 99.5462303817493 % \t time= 31889.20832967758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test==: loss =  0.13337158551490547 \t accuracy= 81.99700262270512 %\n",
      "\n",
      "Train::: epoch= 122 \t lr= 0.01593154088551783 \t (loss)= 0.0025135403738859256 \t (accuracy)= 99.53165979767704 % \t time= 32151.854460716248\n",
      "Test==: loss =  0.1349987032384996 \t accuracy= 82.0719370550768 %\n",
      "\n",
      "Train::: epoch= 123 \t lr= 0.01593154088551783 \t (loss)= 0.002556492105339859 \t (accuracy)= 99.51500770159444 % \t time= 32414.81303715706\n",
      "Test==: loss =  0.13483545030543717 \t accuracy= 81.92206819033346 %\n",
      "\n",
      "Train::: epoch= 124 \t lr= 0.01593154088551783 \t (loss)= 0.0025111615925314805 \t (accuracy)= 99.537904333708 % \t time= 32680.639077425003\n",
      "Test==: loss =  0.13338000805797512 \t accuracy= 82.24053952791309 %\n",
      "\n",
      "Train::: epoch= 125 \t lr= 0.01593154088551783 \t (loss)= 0.0025060911534077837 \t (accuracy)= 99.53165979767704 % \t time= 32946.93550348282\n",
      "Test==: loss =  0.13348804667158384 \t accuracy= 82.37167478456351 %\n",
      "\n",
      "Train::: epoch= 126 \t lr= 0.01593154088551783 \t (loss)= 0.0024604788801000804 \t (accuracy)= 99.537904333708 % \t time= 33210.443177223206\n",
      "Test==: loss =  0.13259589955235254 \t accuracy= 82.37167478456351 %\n",
      "\n",
      "Train::: epoch= 127 \t lr= 0.01593154088551783 \t (loss)= 0.0024179924013593922 \t (accuracy)= 99.5545564297906 % \t time= 33471.9508702755\n",
      "Test==: loss =  0.13269353837169123 \t accuracy= 82.54027725739978 %\n",
      "\n",
      "Train::: epoch= 128 \t lr= 0.01593154088551783 \t (loss)= 0.002404782556671698 \t (accuracy)= 99.55247491778027 % \t time= 33735.53335738182\n",
      "Test==: loss =  0.1323212531603994 \t accuracy= 82.40914200074934 %\n",
      "\n",
      "Train::: epoch= 129 \t lr= 0.01593154088551783 \t (loss)= 0.002389378083574945 \t (accuracy)= 99.54831189375962 % \t time= 33997.96535348892\n",
      "Test==: loss =  0.1314193129273753 \t accuracy= 82.48407643312102 %\n",
      "\n",
      "Train::: epoch= 130 \t lr= 0.01448321898683439 \t (loss)= 0.0023440704288336532 \t (accuracy)= 99.54831189375962 % \t time= 34258.65335392952\n",
      "Test==: loss =  0.13055092712979244 \t accuracy= 82.59647808167853 %\n",
      "\n",
      "Train::: epoch= 131 \t lr= 0.01448321898683439 \t (loss)= 0.0023013186979005374 \t (accuracy)= 99.54206735772865 % \t time= 34522.301954746246\n",
      "Test==: loss =  0.13035812577964465 \t accuracy= 82.80254777070064 %\n",
      "\n",
      "Train::: epoch= 132 \t lr= 0.01448321898683439 \t (loss)= 0.0022730750314249857 \t (accuracy)= 99.54414886973898 % \t time= 34785.176052093506\n",
      "Test==: loss =  0.12958206169957426 \t accuracy= 82.72761333832896 %\n",
      "\n",
      "Train::: epoch= 133 \t lr= 0.01448321898683439 \t (loss)= 0.002247665751515649 \t (accuracy)= 99.54831189375962 % \t time= 35046.12392830849\n",
      "Test==: loss =  0.12890101527974357 \t accuracy= 82.95241663544398 %\n",
      "\n",
      "Train::: epoch= 134 \t lr= 0.01448321898683439 \t (loss)= 0.00222070599786563 \t (accuracy)= 99.55247491778027 % \t time= 35307.15163898468\n",
      "Test==: loss =  0.12848947973065783 \t accuracy= 83.02735106781566 %\n",
      "\n",
      "Train::: epoch= 135 \t lr= 0.01448321898683439 \t (loss)= 0.0022053402457549902 \t (accuracy)= 99.55039340576995 % \t time= 35569.397411346436\n",
      "Test==: loss =  0.12821306378396266 \t accuracy= 83.10228550018734 %\n",
      "\n",
      "Train::: epoch= 136 \t lr= 0.01448321898683439 \t (loss)= 0.0021893062250730256 \t (accuracy)= 99.5545564297906 % \t time= 35831.297529459\n",
      "Test==: loss =  0.12797997381254553 \t accuracy= 83.13975271637317 %\n",
      "\n",
      "Train::: epoch= 137 \t lr= 0.01448321898683439 \t (loss)= 0.0021734951645996847 \t (accuracy)= 99.5545564297906 % \t time= 36092.19003486633\n",
      "Test==: loss =  0.12772285141574 \t accuracy= 83.13975271637317 %\n",
      "\n",
      "Train::: epoch= 138 \t lr= 0.01448321898683439 \t (loss)= 0.002161190781457307 \t (accuracy)= 99.55247491778027 % \t time= 36355.01851391792\n",
      "Test==: loss =  0.1276310161733882 \t accuracy= 83.06481828400149 %\n",
      "\n",
      "Train::: epoch= 139 \t lr= 0.01448321898683439 \t (loss)= 0.002155168734606125 \t (accuracy)= 99.55247491778027 % \t time= 36614.72356104851\n",
      "Test==: loss =  0.12717111654628926 \t accuracy= 83.06481828400149 %\n",
      "\n",
      "Train::: epoch= 140 \t lr= 0.01316656271530399 \t (loss)= 0.0021103157080229985 \t (accuracy)= 99.54414886973898 % \t time= 36876.505012989044\n",
      "Test==: loss =  0.12591976798099663 \t accuracy= 83.25215436493069 %\n",
      "\n",
      "Train::: epoch= 141 \t lr= 0.01316656271530399 \t (loss)= 0.002082665783155205 \t (accuracy)= 99.54414886973898 % \t time= 37138.15090227127\n",
      "Test==: loss =  0.12582430897188962 \t accuracy= 83.40202322967404 %\n",
      "\n",
      "Train::: epoch= 142 \t lr= 0.01316656271530399 \t (loss)= 0.002081406883557656 \t (accuracy)= 99.55039340576995 % \t time= 37401.33697485924\n",
      "Test==: loss =  0.12536774929867026 \t accuracy= 83.40202322967404 %\n",
      "\n",
      "Train::: epoch= 143 \t lr= 0.01316656271530399 \t (loss)= 0.0020599269489974554 \t (accuracy)= 99.5545564297906 % \t time= 37664.5153362751\n",
      "Test==: loss =  0.12471845616973876 \t accuracy= 83.49569127013862 %\n",
      "\n",
      "Train::: epoch= 144 \t lr= 0.01316656271530399 \t (loss)= 0.002041385354895558 \t (accuracy)= 99.5545564297906 % \t time= 37925.99157118797\n",
      "Test==: loss =  0.12444163195332585 \t accuracy= 83.55189209441738 %\n",
      "\n",
      "Train::: epoch= 145 \t lr= 0.01316656271530399 \t (loss)= 0.0020302989943261325 \t (accuracy)= 99.55247491778027 % \t time= 38186.21431803703\n",
      "Test==: loss =  0.12426730378007972 \t accuracy= 83.51442487823155 %\n",
      "\n",
      "Train::: epoch= 146 \t lr= 0.01316656271530399 \t (loss)= 0.0020349933426074586 \t (accuracy)= 99.55247491778027 % \t time= 38445.38701605797\n",
      "Test==: loss =  0.1241982801925675 \t accuracy= 83.47695766204572 %\n",
      "\n",
      "Train::: epoch= 147 \t lr= 0.01316656271530399 \t (loss)= 0.002015720561857142 \t (accuracy)= 99.55039340576995 % \t time= 38705.51847219467\n",
      "Test==: loss =  0.12409879285190453 \t accuracy= 83.47695766204572 %\n",
      "\n",
      "Train::: epoch= 148 \t lr= 0.01316656271530399 \t (loss)= 0.001997404397790383 \t (accuracy)= 99.55663794180093 % \t time= 38964.91996097565\n",
      "Test==: loss =  0.12397572972607912 \t accuracy= 83.47695766204572 %\n",
      "\n",
      "Train::: epoch= 149 \t lr= 0.01316656271530399 \t (loss)= 0.0019839102032077737 \t (accuracy)= 99.5545564297906 % \t time= 39225.46179437637\n",
      "Test==: loss =  0.12380609470450882 \t accuracy= 83.51442487823155 %\n",
      "\n",
      "Train::: epoch= 150 \t lr= 0.011969602468458171 \t (loss)= 0.0019408414680689903 \t (accuracy)= 99.55039340576995 % \t time= 39486.07133984566\n",
      "Test==: loss =  0.12331109531748681 \t accuracy= 83.62682652678906 %\n",
      "\n",
      "Train::: epoch= 151 \t lr= 0.011969602468458171 \t (loss)= 0.0018964153654441728 \t (accuracy)= 99.5545564297906 % \t time= 39748.07535147667\n",
      "Test==: loss =  0.12313714204434695 \t accuracy= 83.64556013488198 %\n",
      "\n",
      "Train::: epoch= 152 \t lr= 0.011969602468458171 \t (loss)= 0.0018815925055139986 \t (accuracy)= 99.5545564297906 % \t time= 40011.652205467224\n",
      "Test==: loss =  0.12301522214808475 \t accuracy= 83.60809291869614 %\n",
      "\n",
      "Train::: epoch= 153 \t lr= 0.011969602468458171 \t (loss)= 0.0018715401796214636 \t (accuracy)= 99.5545564297906 % \t time= 40273.945820093155\n",
      "Test==: loss =  0.12286966988754025 \t accuracy= 83.60809291869614 %\n",
      "\n",
      "Train::: epoch= 154 \t lr= 0.011969602468458171 \t (loss)= 0.001862742483952019 \t (accuracy)= 99.5545564297906 % \t time= 40537.667100429535\n",
      "Test==: loss =  0.12275620340958973 \t accuracy= 83.60809291869614 %\n",
      "\n",
      "Train::: epoch= 155 \t lr= 0.011969602468458171 \t (loss)= 0.0018550996430753604 \t (accuracy)= 99.5545564297906 % \t time= 40799.86049723625\n",
      "Test==: loss =  0.12264508147526486 \t accuracy= 83.70176095916074 %\n",
      "\n",
      "Train::: epoch= 156 \t lr= 0.011969602468458171 \t (loss)= 0.0018478990886956446 \t (accuracy)= 99.5545564297906 % \t time= 41061.001307964325\n",
      "Test==: loss =  0.12254595110231917 \t accuracy= 83.66429374297489 %\n",
      "\n",
      "Train::: epoch= 157 \t lr= 0.011969602468458171 \t (loss)= 0.0018411505166653708 \t (accuracy)= 99.5545564297906 % \t time= 41325.214503765106\n",
      "Test==: loss =  0.12245316961760011 \t accuracy= 83.66429374297489 %\n",
      "\n",
      "Train::: epoch= 158 \t lr= 0.011969602468458171 \t (loss)= 0.001834702177191716 \t (accuracy)= 99.55663794180093 % \t time= 41586.698607206345\n",
      "Test==: loss =  0.12236671399897867 \t accuracy= 83.66429374297489 %\n",
      "\n",
      "Train::: epoch= 159 \t lr= 0.011969602468458171 \t (loss)= 0.0018285261409989669 \t (accuracy)= 99.55663794180093 % \t time= 41850.859258174896\n",
      "Test==: loss =  0.12228484447228093 \t accuracy= 83.66429374297489 %\n",
      "\n",
      "Train::: epoch= 160 \t lr= 0.010881456789507428 \t (loss)= 0.0017953766505005681 \t (accuracy)= 99.54831189375962 % \t time= 42113.89749407768\n",
      "Test==: loss =  0.1219652881663993 \t accuracy= 83.7579617834395 %\n",
      "\n",
      "Train::: epoch= 161 \t lr= 0.010881456789507428 \t (loss)= 0.0017607387307662019 \t (accuracy)= 99.55247491778027 % \t time= 42375.92044997215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test==: loss =  0.1218725603567849 \t accuracy= 83.7579617834395 %\n",
      "\n",
      "Train::: epoch= 162 \t lr= 0.010881456789507428 \t (loss)= 0.0017510980032019573 \t (accuracy)= 99.55663794180093 % \t time= 42638.79274725914\n",
      "Test==: loss =  0.12178757325783338 \t accuracy= 83.77669539153241 %\n",
      "\n",
      "Train::: epoch= 163 \t lr= 0.010881456789507428 \t (loss)= 0.0017447787189965476 \t (accuracy)= 99.55663794180093 % \t time= 42900.822179317474\n",
      "Test==: loss =  0.1217101141236621 \t accuracy= 83.77669539153241 %\n",
      "\n",
      "Train::: epoch= 164 \t lr= 0.010881456789507428 \t (loss)= 0.0017395514890206907 \t (accuracy)= 99.55663794180093 % \t time= 43163.90292620659\n",
      "Test==: loss =  0.12163943295142332 \t accuracy= 83.77669539153241 %\n",
      "\n",
      "Train::: epoch= 165 \t lr= 0.010881456789507428 \t (loss)= 0.001734843363735887 \t (accuracy)= 99.55663794180093 % \t time= 43428.38034033775\n",
      "Test==: loss =  0.1215746999771375 \t accuracy= 83.81416260771825 %\n",
      "\n",
      "Train::: epoch= 166 \t lr= 0.010881456789507428 \t (loss)= 0.001730443725334242 \t (accuracy)= 99.55663794180093 % \t time= 43690.229031801224\n",
      "Test==: loss =  0.12151500093924424 \t accuracy= 83.83289621581118 %\n",
      "\n",
      "Train::: epoch= 167 \t lr= 0.010881456789507428 \t (loss)= 0.0017262701294928923 \t (accuracy)= 99.55663794180093 % \t time= 43953.620782613754\n",
      "Test==: loss =  0.1214593993099047 \t accuracy= 83.81416260771825 %\n",
      "\n",
      "Train::: epoch= 168 \t lr= 0.010881456789507428 \t (loss)= 0.001722277862352501 \t (accuracy)= 99.55663794180093 % \t time= 44217.38831281662\n",
      "Test==: loss =  0.1214069248377959 \t accuracy= 83.85162982390409 %\n",
      "\n",
      "Train::: epoch= 169 \t lr= 0.010881456789507428 \t (loss)= 0.0017184408532675915 \t (accuracy)= 99.55663794180093 % \t time= 44480.22078585625\n",
      "Test==: loss =  0.12135687843390763 \t accuracy= 83.88909704008992 %\n",
      "\n",
      "Train::: epoch= 170 \t lr= 0.009892233445006752 \t (loss)= 0.001690363400111079 \t (accuracy)= 99.54831189375962 % \t time= 44741.579865932465\n",
      "Test==: loss =  0.12111930697579379 \t accuracy= 83.85162982390409 %\n",
      "\n",
      "Train::: epoch= 171 \t lr= 0.009892233445006752 \t (loss)= 0.001662029031222668 \t (accuracy)= 99.54831189375962 % \t time= 45006.63908290863\n",
      "Test==: loss =  0.12105548119245242 \t accuracy= 83.90783064818284 %\n",
      "\n",
      "Train::: epoch= 172 \t lr= 0.009892233445006752 \t (loss)= 0.0016550661249891165 \t (accuracy)= 99.55039340576995 % \t time= 45270.52386331558\n",
      "Test==: loss =  0.12099464735534014 \t accuracy= 83.94529786436867 %\n",
      "\n",
      "Train::: epoch= 173 \t lr= 0.009892233445006752 \t (loss)= 0.0016507405127910077 \t (accuracy)= 99.55039340576995 % \t time= 45533.49154949188\n",
      "Test==: loss =  0.12093916180543945 \t accuracy= 83.98276508055451 %\n",
      "\n",
      "Train::: epoch= 174 \t lr= 0.009892233445006752 \t (loss)= 0.001647234405058645 \t (accuracy)= 99.55039340576995 % \t time= 45796.41375350952\n",
      "Test==: loss =  0.1208881761992321 \t accuracy= 83.9640314724616 %\n",
      "\n",
      "Train::: epoch= 175 \t lr= 0.009892233445006752 \t (loss)= 0.001644078352980473 \t (accuracy)= 99.55039340576995 % \t time= 46058.06424498558\n",
      "Test==: loss =  0.1208406247500603 \t accuracy= 83.94529786436867 %\n",
      "\n",
      "Train::: epoch= 176 \t lr= 0.009892233445006752 \t (loss)= 0.0016411218462031028 \t (accuracy)= 99.55039340576995 % \t time= 46320.057007074356\n",
      "Test==: loss =  0.12079604504029208 \t accuracy= 83.94529786436867 %\n",
      "\n",
      "Train::: epoch= 177 \t lr= 0.009892233445006752 \t (loss)= 0.0016382990150310022 \t (accuracy)= 99.55039340576995 % \t time= 46582.31805944443\n",
      "Test==: loss =  0.12075391656281549 \t accuracy= 83.9640314724616 %\n",
      "\n",
      "Train::: epoch= 178 \t lr= 0.009892233445006752 \t (loss)= 0.0016355775843445296 \t (accuracy)= 99.55039340576995 % \t time= 46842.93428325653\n",
      "Test==: loss =  0.12071381095809917 \t accuracy= 83.94529786436867 %\n",
      "\n",
      "Train::: epoch= 179 \t lr= 0.009892233445006752 \t (loss)= 0.0016329447963963966 \t (accuracy)= 99.55039340576995 % \t time= 47104.64800405502\n",
      "Test==: loss =  0.1206753672052867 \t accuracy= 83.98276508055451 %\n",
      "\n",
      "Train::: epoch= 180 \t lr= 0.008992939495460683 \t (loss)= 0.0016084158995704105 \t (accuracy)= 99.55039340576995 % \t time= 47366.57647252083\n",
      "Test==: loss =  0.12048724219541909 \t accuracy= 83.98276508055451 %\n",
      "\n",
      "Train::: epoch= 181 \t lr= 0.008992939495460683 \t (loss)= 0.0015849575237437974 \t (accuracy)= 99.5545564297906 % \t time= 47627.71303153038\n",
      "Test==: loss =  0.12043700509039602 \t accuracy= 83.98276508055451 %\n",
      "\n",
      "Train::: epoch= 182 \t lr= 0.008992939495460683 \t (loss)= 0.001579552085364169 \t (accuracy)= 99.5545564297906 % \t time= 47887.076078891754\n",
      "Test==: loss =  0.120389033566735 \t accuracy= 83.98276508055451 %\n",
      "\n",
      "Train::: epoch= 183 \t lr= 0.008992939495460683 \t (loss)= 0.0015763315590321123 \t (accuracy)= 99.5545564297906 % \t time= 48150.231544971466\n",
      "Test==: loss =  0.12034511173989046 \t accuracy= 84.00149868864743 %\n",
      "\n",
      "Train::: epoch= 184 \t lr= 0.008992939495460683 \t (loss)= 0.001573772425715308 \t (accuracy)= 99.5545564297906 % \t time= 48409.41029024124\n",
      "Test==: loss =  0.12030455472966699 \t accuracy= 84.00149868864743 %\n",
      "\n",
      "Train::: epoch= 185 \t lr= 0.008992939495460683 \t (loss)= 0.001571485342385729 \t (accuracy)= 99.5545564297906 % \t time= 48669.83070516586\n",
      "Test==: loss =  0.12026677369443411 \t accuracy= 84.00149868864743 %\n",
      "\n",
      "Train::: epoch= 186 \t lr= 0.008992939495460683 \t (loss)= 0.001569344416513943 \t (accuracy)= 99.5545564297906 % \t time= 48931.88620710373\n",
      "Test==: loss =  0.12023137939308878 \t accuracy= 84.00149868864743 %\n",
      "\n",
      "Train::: epoch= 187 \t lr= 0.008992939495460683 \t (loss)= 0.001567290696822378 \t (accuracy)= 99.5545564297906 % \t time= 49194.59716320038\n",
      "Test==: loss =  0.12019793408634144 \t accuracy= 84.00149868864743 %\n",
      "\n",
      "Train::: epoch= 188 \t lr= 0.008992939495460683 \t (loss)= 0.001565306425155403 \t (accuracy)= 99.5545564297906 % \t time= 49455.24452280998\n",
      "Test==: loss =  0.12016630429454858 \t accuracy= 84.00149868864743 %\n",
      "\n",
      "Train::: epoch= 189 \t lr= 0.008992939495460683 \t (loss)= 0.0015633725047324604 \t (accuracy)= 99.5545564297906 % \t time= 49716.00235390663\n",
      "Test==: loss =  0.12013620447882212 \t accuracy= 84.02023229674035 %\n",
      "\n",
      "Train::: epoch= 190 \t lr= 0.008175399541327894 \t (loss)= 0.0015415354086153869 \t (accuracy)= 99.56080096582157 % \t time= 49976.495047330856\n",
      "Test==: loss =  0.1199886094600341 \t accuracy= 83.92656425627575 %\n",
      "\n",
      "Train::: epoch= 191 \t lr= 0.008175399541327894 \t (loss)= 0.0015220649763927352 \t (accuracy)= 99.55871945381125 % \t time= 50235.03577899933\n",
      "Test==: loss =  0.11994910155829437 \t accuracy= 83.92656425627575 %\n",
      "\n",
      "Train::: epoch= 192 \t lr= 0.008175399541327894 \t (loss)= 0.0015176571017808463 \t (accuracy)= 99.55871945381125 % \t time= 50496.42832279205\n",
      "Test==: loss =  0.1199104197928025 \t accuracy= 83.92656425627575 %\n",
      "\n",
      "Train::: epoch= 193 \t lr= 0.008175399541327894 \t (loss)= 0.0015151134133282351 \t (accuracy)= 99.55871945381125 % \t time= 50757.991015672684\n",
      "Test==: loss =  0.11987492606747892 \t accuracy= 83.9640314724616 %\n",
      "\n",
      "Train::: epoch= 194 \t lr= 0.008175399541327894 \t (loss)= 0.0015131249756914797 \t (accuracy)= 99.55871945381125 % \t time= 51017.86384057999\n",
      "Test==: loss =  0.11984225826112677 \t accuracy= 83.9640314724616 %\n",
      "\n",
      "Train::: epoch= 195 \t lr= 0.008175399541327894 \t (loss)= 0.0015113639456149769 \t (accuracy)= 99.55871945381125 % \t time= 51279.64326930046\n",
      "Test==: loss =  0.11981182578617977 \t accuracy= 83.98276508055451 %\n",
      "\n",
      "Train::: epoch= 196 \t lr= 0.008175399541327894 \t (loss)= 0.0015097220671884569 \t (accuracy)= 99.55871945381125 % \t time= 51540.1718788147\n",
      "Test==: loss =  0.11978322391799606 \t accuracy= 83.98276508055451 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-df6cb022d9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# backward pass to compute dL/dR, dL/dV and dL/dW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mcombined_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# update the wights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "\n",
    "accu_plt=[]\n",
    "loss_plt=[]\n",
    "test_loss_plt=[]\n",
    "accuracy_test_plt=[]\n",
    "confusion_mtx_parameters=[]\n",
    "# main loop\n",
    "for epoch in range(1,1000):\n",
    "    \n",
    "    # to activate dropout during training \n",
    "    lstm_net.train()\n",
    "    \n",
    "    # divide the learning rate by 3 except after the first epoch\n",
    "    if epoch % 10==0:\n",
    "        my_lr = my_lr / 1.1\n",
    "#         torch.save(lstm_net, 'single_mistake_model_lstm_40_correct_1.pth')\n",
    "    \n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "    lstm_optimizer=torch.optim.SGD( lstm_net.parameters() , lr=my_lr )\n",
    "    \n",
    "   \n",
    "        \n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss = 0\n",
    "    num_batches = 0    \n",
    "    num_matches = 0\n",
    "    \n",
    "    # loop across batch of words\n",
    "    for i in range(0,num_train_words):\n",
    "             # set the initial h and c to be the zero vector\n",
    "        h = torch.zeros(2,batch_of_words,  hidden_size).cuda()\n",
    "        c = torch.zeros(2,batch_of_words,  hidden_size).cuda()\n",
    "        h = h.to(device)\n",
    "        c = c.to(device)\n",
    "        \n",
    "        word_length = len(train_data_1 [i])\n",
    "        \n",
    "        # Set the gradients to zeros\n",
    "        lstm_optimizer.zero_grad()\n",
    "        \n",
    "        # load the data\n",
    "        minibatch_words  = train_data_1[i ]\n",
    "        minibatch_labels = train_labels_1[ i]\n",
    "        \n",
    "        # send to GPU\n",
    "        minibatch_words  = minibatch_words.to(device)\n",
    "        minibatch_labels = minibatch_labels.to(device)\n",
    "\n",
    "        # Detach to prevent from backpropagating all the way to the beginning\n",
    "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
    "        h = h.detach()\n",
    "        c = c.detach()\n",
    "        h = h.requires_grad_()\n",
    "        c = c.requires_grad_()\n",
    "\n",
    "        # forward pass\n",
    "        scores_char, h, c = lstm_net(minibatch_words.view(word_length,1), h, c)\n",
    "\n",
    "        # reshape before calculating the loss for easier slicing of mini batch of words\n",
    "        scores_char = scores_char.view(  word_length*batch_of_words , vocab_size)\n",
    "        minibatch_labels = minibatch_labels.contiguous()\n",
    "        minibatch_labels = minibatch_labels.view(word_length*batch_of_words )\n",
    "        \n",
    "        # calculating the loss of batch of character sthat constrcut a words\n",
    "        loss_char = criterion(scores_char, minibatch_labels)\n",
    "\n",
    "        # summation of both lossses to \n",
    "        combined_loss = loss_char\n",
    "\n",
    "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
    "        combined_loss.backward()\n",
    "\n",
    "        # update the wights \n",
    "        lstm_optimizer.step()\n",
    "\n",
    "        # update the running loss  \n",
    "        running_loss += combined_loss.detach().item()\n",
    "        num_batches += 1\n",
    "        num_matches += get_error(scores_char, minibatch_labels)\n",
    "        \n",
    "        # end of iteration \n",
    "        \n",
    "    # compute for full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    loss_plt.append(total_loss)\n",
    "    accuracy = (num_matches/num_train_words)*100\n",
    "    acc_plt.append(accuracy)\n",
    "    \n",
    "    # Compute the time \n",
    "    elapsed = time.time()-start\n",
    "    \n",
    "    print('')\n",
    "    print('Train:::', 'epoch=',epoch,'\\t lr=', my_lr, '\\t (loss)=',(total_loss),'\\t (accuracy)=' , (accuracy),'%','\\t time=', elapsed)\n",
    "    \n",
    "    # evaluate on test set to monitor the loss \n",
    "    acc_tst_plt, loss_tst_plt, confusion_param=eval_on_test_set()\n",
    "    \n",
    "    # saving test parameters  \n",
    "    test_loss_plt.append(loss_tst_plt)\n",
    "    accuracy_test_plt.append(acc_tst_plt)\n",
    "    confusion_mtx_parameters.append(confusion_param)\n",
    "    #### Saving model parameters every epoch  \n",
    "    save_model_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_net, 'this_morning_wo_do.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'single_mistake_model_lstm_40_correct_2.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-b0e0e269aaa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'single_mistake_model_lstm_40_correct_2.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'single_mistake_model_lstm_40_correct_2.pt'"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('single_mistake_model_lstm_40_correct_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5293.0]\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint['correct_to_correct'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
