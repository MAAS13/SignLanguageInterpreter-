{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import random_split\n",
    "import math\n",
    "import string\n",
    "\n",
    "from global_defs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1=torch.load('train_data_50_mut_1_c.pt')\n",
    "test_data_1=torch.load('test_data_50_mut_1_c.pt')\n",
    "train_labels_1=torch.load('train_labels_50_mut_1_c.pt')\n",
    "test_labels_1=torch.load('test_labels_50_mut_1_c.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_words=len(train_data_1)\n",
    "num_test_words=len(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_words=48042 # 1000 words 50 misspilled single mistake \n",
    "num_test_words=5338 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recurrent_Layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(Recurrent_Layer, self).__init__()\n",
    "        \n",
    "\n",
    "        self.layer1 = nn.Embedding (vocab_size, hidden_size)\n",
    "        self.lstm=nn.LSTM( hidden_size, hidden_size) #bidirectional=True\n",
    "#         self.dropout=nn.Dropout(0.2)\n",
    "        self.fc=nn.Linear( hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h_init,c_init):\n",
    "\n",
    "        g_seq          =self.layer1(x)\n",
    "        h_seq, (h_final, c_final) =self.lstm(g_seq, (h_init,c_init))\n",
    "#         h_seq=self.dropout(h_seq)\n",
    "        score_seq      =self.fc(h_seq)\n",
    "        \n",
    "        return score_seq,  h_final , c_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recurrent_Layer(\n",
      "  (layer1): Embedding(26, 256)\n",
      "  (lstm): LSTM(256, 256)\n",
      "  (fc): Linear(in_features=256, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size=256\n",
    "vocab_size =26\n",
    "# word_length= 19 #  according to the data \n",
    "batch_of_words=1\n",
    "\n",
    "lstm_net=Recurrent_Layer(vocab_size,hidden_size).cuda()\n",
    "\n",
    "lstm_net = lstm_net.to(device)\n",
    "print(lstm_net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr=0.05\n",
    "accu_plt=[]\n",
    "loss_plt=[]\n",
    "test_loss_plt=[]\n",
    "accuracy_test_plt=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error( scores , labels ):\n",
    "\n",
    "    bs=scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_matches=indicator.sum()\n",
    "    corr=num_matches/len(predicted_labels)\n",
    "    return corr.item()\n",
    "\n",
    "def save_model_parameters():\n",
    "# save models \n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'lstm_model':lstm_net.state_dict(),\n",
    "                'lstm_optimizer': lstm_optimizer.state_dict(),\n",
    "                'train_loss': loss_plt, 'train_accuracy': accu_plt, \n",
    "                'test_loss': test_loss_plt,\n",
    "                'test_accuracy': accuracy_test_plt, 'confusion matrix_parameters':confusion_mtx_parameters  }, 'lstm_single_Basic Model.pt')\n",
    "#                 'incorrect_to_correct':confusion_mtx_parameters[0],  'correct_to_correct':confusion_mtx_parameters[2],\n",
    "#                 'correct_to_incorrect':confusion_mtx_parameters[1],'regenerate':confusion_mtx_parameters[3]\n",
    "  \n",
    "           \n",
    "               \n",
    "     \n",
    "        #print(in_word, out_word)\n",
    "        \n",
    "def confusion_parameters(scores,target_tensor,inpute_tensor,conf_counter):\n",
    "\n",
    "    \n",
    "    if torch.all(torch.eq(target_tensor, scores.argmax(dim=1)))==1 and torch.all(torch.eq(inpute_tensor,target_tensor))==0: ### making incorrect->correct\n",
    "        conf_counter[0] +=1\n",
    "\n",
    "    if torch.all(torch.eq(inpute_tensor, scores.argmax(dim=1)))==0 and torch.all(torch.eq(inpute_tensor,target_tensor))==1: ### making correct->incorrect\n",
    "\n",
    "        conf_counter[1] +=1    \n",
    "\n",
    "\n",
    "    if torch.all(torch.eq(inpute_tensor, scores.argmax(dim=1)))==1 and torch.all(torch.eq(inpute_tensor,target_tensor))==1: ### making correct->correct\n",
    "\n",
    "        conf_counter[2] +=1                                                               \n",
    "\n",
    "    if torch.all(torch.eq(inpute_tensor, scores.argmax(dim=1)))==1 and torch.all(torch.eq(inpute_tensor,target_tensor))==0: ### making inccorrect->correct or regenerate the input \n",
    "\n",
    "        conf_counter[3] +=1  \n",
    "    return conf_counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "    # to deactivate dropout regularization during testing\n",
    "    lstm_net.eval()\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "    num_matches=0 \n",
    "    acc_plt=[]\n",
    "    loss_plt=[]\n",
    "    \n",
    "    # counts for computing correct and incorrect proportion\n",
    "    count=torch.zeros(4)\n",
    "    cnt_list=torch.zeros(4)\n",
    "    cnf_mtx_count=torch.zeros(4)\n",
    "    \n",
    "    for i in range(0,num_test_words):\n",
    "        \n",
    "        h = torch.zeros(1,batch_of_words,  hidden_size).cuda()\n",
    "        c = torch.zeros(1,batch_of_words,  hidden_size).cuda()\n",
    "        h=h.to(device)\n",
    "        c=c.to(device)\n",
    "        word_length= len(test_data_1 [i])\n",
    "        \n",
    "        inpute_tensor=  test_data_1[i].cuda()\n",
    "        target_tensor =  test_labels_1[i].cuda()\n",
    "        \n",
    "        # sending to GPU\n",
    "        inpute_tensor=inpute_tensor.to(device)\n",
    "        target_tensor=target_tensor.to(device)\n",
    "        # forward pass\n",
    "        scores_char, h, c= lstm_net(inpute_tensor.view(word_length,1), h, c)\n",
    "        # reshape before calculating the loss for easier slicing of mini batch of words\n",
    "        scores_char = scores_char.view(word_length*batch_of_words,vocab_size)\n",
    "        target_tensor = target_tensor.contiguous()\n",
    "        target_tensor = target_tensor.view(word_length*batch_of_words)\n",
    "        # calculating the loss of batch of character sthat constrcut a words\n",
    "        loss_char= criterion(scores_char, target_tensor)# do we need to add the loss for every \n",
    "        \n",
    "            #================================================#\n",
    "        # accumalate the loss\n",
    "        running_loss+= loss_char.item()\n",
    "        num_batches+=1 \n",
    "        # computing accuracy\n",
    "        num_matches+= get_error(scores_char, target_tensor)\n",
    "        #=======================================================#\n",
    "        # compute confusion paramters \n",
    "        cnf_mtx_count+=confusion_parameters(scores_char,target_tensor,inpute_tensor,count)\n",
    "        #============================================# \n",
    "        \n",
    "\n",
    "    ###====Different Metrics for evaluation=============###\n",
    "    \n",
    "    # counter for computing confusion matrix\n",
    "#     cnt_list[0]+=cnf_mtx_count[0].item()\n",
    "#     cnt_list[1]+=cnf_mtx_count[1].item()\n",
    "#     cnt_list[2]+=cnf_mtx_count[2].item()\n",
    "#     cnt_list[3]+=cnf_mtx_count[3].item()\n",
    "  \n",
    "    # accuracy and loss \n",
    "    accuracy= (num_matches/num_test_words)*100\n",
    "    acc_plt.append(accuracy)\n",
    "    total_loss = running_loss/num_batches \n",
    "    loss_plt.append(total_loss)\n",
    "    \n",
    "    # printing results \n",
    "    print('Test==: loss = ',(total_loss),'\\t accuracy=', accuracy,'%' )\n",
    "    return acc_plt, loss_plt, cnf_mtx_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test==: loss =  0.6082124173641205 \t accuracy= 20.0 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([20.0], [0.6082124173641205], tensor([9., 1., 6., 0.]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_on_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train::: epoch= 1 \t lr= 0.05 \t (loss)= 0.19623494833344096 \t (accuracy)= 63.76920194829524 % \t time= 237.37316846847534\n",
      "Test==: loss =  1.7910580363430106 \t accuracy= 0.9554140127388535 %\n",
      "\n",
      "Train::: epoch= 2 \t lr= 0.05 \t (loss)= 0.1517772299977759 \t (accuracy)= 71.13775446484325 % \t time= 494.4772083759308\n",
      "Test==: loss =  1.8183493763665937 \t accuracy= 1.2551517422255525 %\n",
      "\n",
      "Train::: epoch= 3 \t lr= 0.05 \t (loss)= 0.1447985073098206 \t (accuracy)= 72.27842304650099 % \t time= 734.1031839847565\n",
      "Test==: loss =  1.5837755915668494 \t accuracy= 1.6860247283626826 %\n",
      "\n",
      "Train::: epoch= 4 \t lr= 0.05 \t (loss)= 0.13700752401204647 \t (accuracy)= 73.59185712501561 % \t time= 898.3399035930634\n",
      "Test==: loss =  1.617262648749734 \t accuracy= 1.798426376920195 %\n",
      "\n",
      "Train::: epoch= 5 \t lr= 0.05 \t (loss)= 0.13228594369850588 \t (accuracy)= 74.54935264976478 % \t time= 1158.6797499656677\n",
      "Test==: loss =  1.5870880829217127 \t accuracy= 2.341701011614837 %\n",
      "\n",
      "Train::: epoch= 6 \t lr= 0.05 \t (loss)= 0.12496166629831734 \t (accuracy)= 75.80450439199035 % \t time= 1420.6731119155884\n",
      "Test==: loss =  1.4809077205999066 \t accuracy= 2.43536905207943 %\n",
      "\n",
      "Train::: epoch= 7 \t lr= 0.05 \t (loss)= 0.12037223751119198 \t (accuracy)= 76.5122184755006 % \t time= 1683.0495941638947\n",
      "Test==: loss =  1.4274413647108946 \t accuracy= 2.772573997751967 %\n",
      "\n",
      "Train::: epoch= 8 \t lr= 0.05 \t (loss)= 0.11276549762276335 \t (accuracy)= 77.7527996336539 % \t time= 1945.2386186122894\n",
      "Test==: loss =  1.3550257961540075 \t accuracy= 2.9973772948669914 %\n",
      "\n",
      "Train::: epoch= 9 \t lr= 0.05 \t (loss)= 0.10858628589780973 \t (accuracy)= 78.61662711793848 % \t time= 2206.157938718796\n",
      "Test==: loss =  1.261906564735692 \t accuracy= 3.840389659048333 %\n",
      "\n",
      "Train::: epoch= 10 \t lr= 0.045454545454545456 \t (loss)= 0.10564605210056466 \t (accuracy)= 78.8331043670122 % \t time= 2466.903422355652\n",
      "Test==: loss =  1.190598612215424 \t accuracy= 3.9902585237916823 %\n",
      "\n",
      "Train::: epoch= 11 \t lr= 0.045454545454545456 \t (loss)= 0.09856289042108116 \t (accuracy)= 80.11947878939262 % \t time= 2727.716451883316\n",
      "Test==: loss =  1.1062370957607266 \t accuracy= 4.233795428999625 %\n",
      "\n",
      "Train::: epoch= 12 \t lr= 0.045454545454545456 \t (loss)= 0.09197832986420237 \t (accuracy)= 81.22684317888515 % \t time= 2990.3743681907654\n",
      "Test==: loss =  1.125073228749266 \t accuracy= 4.3087298613713 %\n",
      "\n",
      "Train::: epoch= 13 \t lr= 0.045454545454545456 \t (loss)= 0.0858840001880541 \t (accuracy)= 82.42787560884226 % \t time= 3251.402323961258\n",
      "Test==: loss =  1.0995521208272212 \t accuracy= 4.477332334207569 %\n",
      "\n",
      "Train::: epoch= 14 \t lr= 0.045454545454545456 \t (loss)= 0.08071388127862093 \t (accuracy)= 83.17305690853837 % \t time= 3510.827929496765\n",
      "Test==: loss =  1.1542297151202412 \t accuracy= 4.627201198950917 %\n",
      "\n",
      "Train::: epoch= 15 \t lr= 0.045454545454545456 \t (loss)= 0.07544673788589196 \t (accuracy)= 84.20964988967987 % \t time= 3773.054720878601\n",
      "Test==: loss =  1.1751212793070422 \t accuracy= 4.589733982765081 %\n",
      "\n",
      "Train::: epoch= 16 \t lr= 0.045454545454545456 \t (loss)= 0.07081099499807843 \t (accuracy)= 85.16298239040839 % \t time= 4031.360769510269\n",
      "Test==: loss =  1.0892410056740824 \t accuracy= 4.777070063694268 %\n",
      "\n",
      "Train::: epoch= 17 \t lr= 0.045454545454545456 \t (loss)= 0.06772064985744301 \t (accuracy)= 85.53765455226676 % \t time= 4291.252312660217\n",
      "Test==: loss =  1.1190448392099481 \t accuracy= 4.777070063694268 %\n",
      "\n",
      "Train::: epoch= 18 \t lr= 0.045454545454545456 \t (loss)= 0.06388034187516332 \t (accuracy)= 86.26202073185962 % \t time= 4551.796135187149\n",
      "Test==: loss =  1.1596000394261103 \t accuracy= 4.645934807043837 %\n",
      "\n",
      "Train::: epoch= 19 \t lr= 0.045454545454545456 \t (loss)= 0.06106560438849909 \t (accuracy)= 86.94267515923568 % \t time= 4811.708424568176\n",
      "Test==: loss =  1.179106656152028 \t accuracy= 4.777070063694268 %\n",
      "\n",
      "Train::: epoch= 20 \t lr= 0.04132231404958678 \t (loss)= 0.05924752092896263 \t (accuracy)= 87.27363556887722 % \t time= 5071.376515388489\n",
      "Test==: loss =  1.1769557796038808 \t accuracy= 4.7583364556013485 %\n",
      "\n",
      "Train::: epoch= 21 \t lr= 0.04132231404958678 \t (loss)= 0.056391160277009196 \t (accuracy)= 87.84396985970609 % \t time= 5332.3243136405945\n",
      "Test==: loss =  1.178087912304596 \t accuracy= 4.627201198950917 %\n",
      "\n",
      "Train::: epoch= 22 \t lr= 0.04132231404958678 \t (loss)= 0.054255375230116434 \t (accuracy)= 88.25402772573997 % \t time= 5595.4687304496765\n",
      "Test==: loss =  1.1618502523049066 \t accuracy= 4.7583364556013485 %\n",
      "\n",
      "Train::: epoch= 23 \t lr= 0.04132231404958678 \t (loss)= 0.05333057867470544 \t (accuracy)= 88.49340160692726 % \t time= 5859.087611198425\n",
      "Test==: loss =  1.1910351407231041 \t accuracy= 4.777070063694268 %\n",
      "\n",
      "Train::: epoch= 24 \t lr= 0.04132231404958678 \t (loss)= 0.05193755436773707 \t (accuracy)= 88.81811748053786 % \t time= 6122.719754695892\n",
      "Test==: loss =  1.237467525778624 \t accuracy= 4.702135631322593 %\n",
      "\n",
      "Train::: epoch= 25 \t lr= 0.04132231404958678 \t (loss)= 0.05014317030017384 \t (accuracy)= 89.22609383456142 % \t time= 6386.427507400513\n",
      "Test==: loss =  1.222777287675791 \t accuracy= 4.702135631322593 %\n",
      "\n",
      "Train::: epoch= 26 \t lr= 0.04132231404958678 \t (loss)= 0.049150794002442724 \t (accuracy)= 89.30310977894342 % \t time= 6650.645916223526\n",
      "Test==: loss =  1.2031980140084522 \t accuracy= 4.87073810415886 %\n",
      "\n",
      "Train::: epoch= 27 \t lr= 0.04132231404958678 \t (loss)= 0.04878055058898493 \t (accuracy)= 89.47171225177969 % \t time= 6915.057025909424\n",
      "Test==: loss =  1.2632786967764351 \t accuracy= 4.7583364556013485 %\n",
      "\n",
      "Train::: epoch= 28 \t lr= 0.04132231404958678 \t (loss)= 0.04765661878497671 \t (accuracy)= 89.59452146038883 % \t time= 7181.973569393158\n",
      "Test==: loss =  1.280123221810027 \t accuracy= 4.777070063694268 %\n",
      "\n",
      "Train::: epoch= 29 \t lr= 0.04132231404958678 \t (loss)= 0.04760599900762621 \t (accuracy)= 89.75063486116315 % \t time= 7447.239170789719\n",
      "Test==: loss =  1.300388112883386 \t accuracy= 4.777070063694268 %\n",
      "\n",
      "Train::: epoch= 30 \t lr= 0.037565740045078885 \t (loss)= 0.04769836293762028 \t (accuracy)= 89.70067857291536 % \t time= 7712.0813410282135\n",
      "Test==: loss =  1.3213798668703889 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 31 \t lr= 0.037565740045078885 \t (loss)= 0.04678434509135368 \t (accuracy)= 89.85262894966904 % \t time= 7977.628947973251\n",
      "Test==: loss =  1.3688394427054151 \t accuracy= 4.908205320344698 %\n",
      "\n",
      "Train::: epoch= 32 \t lr= 0.037565740045078885 \t (loss)= 0.0457031615389815 \t (accuracy)= 90.1398776070938 % \t time= 8242.981999874115\n",
      "Test==: loss =  1.4025959095758314 \t accuracy= 4.87073810415886 %\n",
      "\n",
      "Train::: epoch= 33 \t lr= 0.037565740045078885 \t (loss)= 0.04553269103889003 \t (accuracy)= 90.04829107863952 % \t time= 8509.04192328453\n",
      "Test==: loss =  1.413930371741406 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 34 \t lr= 0.037565740045078885 \t (loss)= 0.0454276873649935 \t (accuracy)= 90.14195911910411 % \t time= 8774.147347688675\n",
      "Test==: loss =  1.4526654692951462 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 35 \t lr= 0.037565740045078885 \t (loss)= 0.044883689710335115 \t (accuracy)= 90.14820365513509 % \t time= 9040.186692476273\n",
      "Test==: loss =  1.4288600738961394 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 36 \t lr= 0.037565740045078885 \t (loss)= 0.04447492509360407 \t (accuracy)= 90.28350193580617 % \t time= 9310.938548326492\n",
      "Test==: loss =  1.4459265152061693 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 37 \t lr= 0.037565740045078885 \t (loss)= 0.0442497371212052 \t (accuracy)= 90.29390949585779 % \t time= 9573.388059616089\n",
      "Test==: loss =  1.4939872311530085 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 38 \t lr= 0.037565740045078885 \t (loss)= 0.04365524686960829 \t (accuracy)= 90.57283210524125 % \t time= 9834.537845134735\n",
      "Test==: loss =  1.4755440371822477 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 39 \t lr= 0.037565740045078885 \t (loss)= 0.04399973534775093 \t (accuracy)= 90.28766495982681 % \t time= 10096.583215475082\n",
      "Test==: loss =  1.4581015547084557 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 40 \t lr= 0.03415067276825353 \t (loss)= 0.04413597024968534 \t (accuracy)= 90.41880021647725 % \t time= 10356.866096735\n",
      "Test==: loss =  1.439795130640339 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 41 \t lr= 0.03415067276825353 \t (loss)= 0.04324767105234794 \t (accuracy)= 90.57283210524125 % \t time= 10616.604407310486\n",
      "Test==: loss =  1.4302400729616713 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 42 \t lr= 0.03415067276825353 \t (loss)= 0.042832430284584104 \t (accuracy)= 90.57699512926189 % \t time= 10876.143733263016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test==: loss =  1.4456238837407545 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 43 \t lr= 0.03415067276825353 \t (loss)= 0.04221329948381605 \t (accuracy)= 90.72270096998459 % \t time= 11136.974091291428\n",
      "Test==: loss =  1.4665848931223138 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 44 \t lr= 0.03415067276825353 \t (loss)= 0.04188556457186938 \t (accuracy)= 90.88714041880021 % \t time= 11396.205334663391\n",
      "Test==: loss =  1.4324966244434256 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 45 \t lr= 0.03415067276825353 \t (loss)= 0.041110777096126164 \t (accuracy)= 91.00162357936806 % \t time= 11654.50598192215\n",
      "Test==: loss =  1.4281510243512656 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 46 \t lr= 0.03415067276825353 \t (loss)= 0.04105228658880757 \t (accuracy)= 90.89754797885183 % \t time= 11913.10919046402\n",
      "Test==: loss =  1.4236699732366545 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 47 \t lr= 0.03415067276825353 \t (loss)= 0.041343583701011564 \t (accuracy)= 90.89754797885183 % \t time= 12170.489255189896\n",
      "Test==: loss =  1.413786915865785 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 48 \t lr= 0.03415067276825353 \t (loss)= 0.0412051541049935 \t (accuracy)= 90.94750426709962 % \t time= 12427.881651163101\n",
      "Test==: loss =  1.3978552188044526 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 49 \t lr= 0.03415067276825353 \t (loss)= 0.04140822808177031 \t (accuracy)= 90.77890179426336 % \t time= 12688.030585765839\n",
      "Test==: loss =  1.4095553683125077 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 50 \t lr= 0.03104606615295775 \t (loss)= 0.04227530773678464 \t (accuracy)= 90.5874026893135 % \t time= 12944.780357837677\n",
      "Test==: loss =  1.4045539014920747 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 51 \t lr= 0.03104606615295775 \t (loss)= 0.04163873549904623 \t (accuracy)= 90.73727155405686 % \t time= 13199.901035785675\n",
      "Test==: loss =  1.4246820134486926 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 52 \t lr= 0.03104606615295775 \t (loss)= 0.04161420292893682 \t (accuracy)= 90.78930935431498 % \t time= 13455.749501228333\n",
      "Test==: loss =  1.4178803136071039 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 53 \t lr= 0.03104606615295775 \t (loss)= 0.041347264787945044 \t (accuracy)= 90.86632529869696 % \t time= 13711.982765197754\n",
      "Test==: loss =  1.439351020807855 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 54 \t lr= 0.03104606615295775 \t (loss)= 0.04138173629576853 \t (accuracy)= 90.81428749843886 % \t time= 13968.423055171967\n",
      "Test==: loss =  1.456724112396661 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 55 \t lr= 0.03104606615295775 \t (loss)= 0.04147044371181117 \t (accuracy)= 90.79347237833562 % \t time= 14227.488654375076\n",
      "Test==: loss =  1.4658462004093524 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 56 \t lr= 0.03104606615295775 \t (loss)= 0.0411230641203498 \t (accuracy)= 90.7747387702427 % \t time= 14486.837626934052\n",
      "Test==: loss =  1.4382914940743323 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 57 \t lr= 0.03104606615295775 \t (loss)= 0.041232471060002246 \t (accuracy)= 90.68107072977811 % \t time= 14745.589606523514\n",
      "Test==: loss =  1.370483235749379 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 58 \t lr= 0.03104606615295775 \t (loss)= 0.04111962044537489 \t (accuracy)= 90.72686399400524 % \t time= 15001.050637722015\n",
      "Test==: loss =  1.3869490315676754 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 59 \t lr= 0.03104606615295775 \t (loss)= 0.040578320042879854 \t (accuracy)= 91.03076474751259 % \t time= 15261.571016788483\n",
      "Test==: loss =  1.326617872150046 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 60 \t lr= 0.028223696502688862 \t (loss)= 0.04194744087589624 \t (accuracy)= 90.52703884101412 % \t time= 15520.920683860779\n",
      "Test==: loss =  1.3167848696847986 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 61 \t lr= 0.028223696502688862 \t (loss)= 0.041637311498110875 \t (accuracy)= 90.62695141750969 % \t time= 15779.285407781601\n",
      "Test==: loss =  1.326745993831561 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 62 \t lr= 0.028223696502688862 \t (loss)= 0.04148956808375882 \t (accuracy)= 90.61238083343741 % \t time= 16036.217569112778\n",
      "Test==: loss =  1.3315483108994932 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 63 \t lr= 0.028223696502688862 \t (loss)= 0.041050084404806994 \t (accuracy)= 90.7143749219433 % \t time= 16293.353098154068\n",
      "Test==: loss =  1.339904658608824 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 64 \t lr= 0.028223696502688862 \t (loss)= 0.040782886873378665 \t (accuracy)= 90.78722784230465 % \t time= 16550.607218265533\n",
      "Test==: loss =  1.3363359266301376 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 65 \t lr= 0.028223696502688862 \t (loss)= 0.041167618985175326 \t (accuracy)= 90.63944048957163 % \t time= 16806.34701371193\n",
      "Test==: loss =  1.3351162317753202 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 66 \t lr= 0.028223696502688862 \t (loss)= 0.041299837577287016 \t (accuracy)= 90.54993547312769 % \t time= 17065.064525604248\n",
      "Test==: loss =  1.3313093952625445 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 67 \t lr= 0.028223696502688862 \t (loss)= 0.04167440975882637 \t (accuracy)= 90.53328337704508 % \t time= 17321.047116279602\n",
      "Test==: loss =  1.3204014312256172 \t accuracy= 4.908205320344698 %\n",
      "\n",
      "Train::: epoch= 68 \t lr= 0.028223696502688862 \t (loss)= 0.041863498896514036 \t (accuracy)= 90.53120186503476 % \t time= 17576.504910945892\n",
      "Test==: loss =  1.3169515204954567 \t accuracy= 4.87073810415886 %\n",
      "\n",
      "Train::: epoch= 69 \t lr= 0.028223696502688862 \t (loss)= 0.042423624785981946 \t (accuracy)= 90.45418592065276 % \t time= 17834.110083818436\n",
      "Test==: loss =  1.2931058322096134 \t accuracy= 4.908205320344698 %\n",
      "\n",
      "Train::: epoch= 70 \t lr= 0.025657905911535328 \t (loss)= 0.04405907953633473 \t (accuracy)= 90.01082386245368 % \t time= 18090.97763967514\n",
      "Test==: loss =  1.2858419583348957 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 71 \t lr= 0.025657905911535328 \t (loss)= 0.04340837668881095 \t (accuracy)= 90.22105657549643 % \t time= 18346.433126688004\n",
      "Test==: loss =  1.2596656063180238 \t accuracy= 4.908205320344698 %\n",
      "\n",
      "Train::: epoch= 72 \t lr= 0.025657905911535328 \t (loss)= 0.04330818816308042 \t (accuracy)= 90.2606053036926 % \t time= 18602.432849168777\n",
      "Test==: loss =  1.2707199310518549 \t accuracy= 4.908205320344698 %\n",
      "\n",
      "Train::: epoch= 73 \t lr= 0.025657905911535328 \t (loss)= 0.04281195547785284 \t (accuracy)= 90.36676241621913 % \t time= 18857.859729766846\n",
      "Test==: loss =  1.2746812127058509 \t accuracy= 4.908205320344698 %\n",
      "\n",
      "Train::: epoch= 74 \t lr= 0.025657905911535328 \t (loss)= 0.042752886452981864 \t (accuracy)= 90.30639856791973 % \t time= 19113.004058599472\n",
      "Test==: loss =  1.2852309665798172 \t accuracy= 4.926938928437617 %\n",
      "\n",
      "Train::: epoch= 75 \t lr= 0.025657905911535328 \t (loss)= 0.042803298061797994 \t (accuracy)= 90.20648599142417 % \t time= 19367.979726552963\n",
      "Test==: loss =  1.3048404514250487 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 76 \t lr= 0.025657905911535328 \t (loss)= 0.0429074086737466 \t (accuracy)= 90.30848007993006 % \t time= 19623.273349523544\n",
      "Test==: loss =  1.330428037388484 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 77 \t lr= 0.025657905911535328 \t (loss)= 0.04385093835528973 \t (accuracy)= 89.94629699013363 % \t time= 19879.877542495728\n",
      "Test==: loss =  1.3484502512333967 \t accuracy= 4.88947171225178 %\n",
      "\n",
      "Train::: epoch= 78 \t lr= 0.025657905911535328 \t (loss)= 0.04462742424551983 \t (accuracy)= 89.89842221389618 % \t time= 20134.7715280056\n",
      "Test==: loss =  1.3688790737779852 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 79 \t lr= 0.025657905911535328 \t (loss)= 0.045242579362824636 \t (accuracy)= 89.72565671703926 % \t time= 20389.809533834457\n",
      "Test==: loss =  1.4071860728206615 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 80 \t lr= 0.02332536901048666 \t (loss)= 0.046454967950685065 \t (accuracy)= 89.3946963073977 % \t time= 20643.897430181503\n",
      "Test==: loss =  1.4064362040378513 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 81 \t lr= 0.02332536901048666 \t (loss)= 0.04629378788558885 \t (accuracy)= 89.38428874734608 % \t time= 20897.857197761536\n",
      "Test==: loss =  1.4308269208714155 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 82 \t lr= 0.02332536901048666 \t (loss)= 0.0456598927021842 \t (accuracy)= 89.5924399483785 % \t time= 21155.372802495956\n",
      "Test==: loss =  1.4195907754531376 \t accuracy= 5.02060696890221 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train::: epoch= 83 \t lr= 0.02332536901048666 \t (loss)= 0.04608401738402703 \t (accuracy)= 89.56329878023396 % \t time= 21414.329174041748\n",
      "Test==: loss =  1.3751255180756985 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 84 \t lr= 0.02332536901048666 \t (loss)= 0.045794299804838456 \t (accuracy)= 89.6861079888431 % \t time= 21673.379717111588\n",
      "Test==: loss =  1.3637913279448632 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 85 \t lr= 0.02332536901048666 \t (loss)= 0.045959883027646545 \t (accuracy)= 89.62782565255402 % \t time= 21933.178502559662\n",
      "Test==: loss =  1.3358917743203014 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 86 \t lr= 0.02332536901048666 \t (loss)= 0.045847598629600424 \t (accuracy)= 89.55080970817203 % \t time= 22192.35643339157\n",
      "Test==: loss =  1.3224688436811365 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 87 \t lr= 0.02332536901048666 \t (loss)= 0.04615826848019319 \t (accuracy)= 89.55080970817203 % \t time= 22452.343126296997\n",
      "Test==: loss =  1.3348343094356998 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 88 \t lr= 0.02332536901048666 \t (loss)= 0.04563427253464099 \t (accuracy)= 89.52791307605845 % \t time= 22714.504384994507\n",
      "Test==: loss =  1.33126829493086 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 89 \t lr= 0.02332536901048666 \t (loss)= 0.04580270824364179 \t (accuracy)= 89.53415761208943 % \t time= 22974.743629693985\n",
      "Test==: loss =  1.3726894653974089 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 90 \t lr= 0.021204880918624235 \t (loss)= 0.046861871775310385 \t (accuracy)= 89.32808792306732 % \t time= 23239.62260055542\n",
      "Test==: loss =  1.3895879110125018 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 91 \t lr= 0.021204880918624235 \t (loss)= 0.04618005983351003 \t (accuracy)= 89.4467341076558 % \t time= 23501.99796152115\n",
      "Test==: loss =  1.3850768837557086 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 92 \t lr= 0.021204880918624235 \t (loss)= 0.04567763790958567 \t (accuracy)= 89.61117355647143 % \t time= 23763.79478287697\n",
      "Test==: loss =  1.3615002310311723 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 93 \t lr= 0.021204880918624235 \t (loss)= 0.045630175873427194 \t (accuracy)= 89.6528037966779 % \t time= 24024.515041589737\n",
      "Test==: loss =  1.3599016320464463 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 94 \t lr= 0.021204880918624235 \t (loss)= 0.04577165486210017 \t (accuracy)= 89.45089713167646 % \t time= 24285.33917284012\n",
      "Test==: loss =  1.3523571651240056 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 95 \t lr= 0.021204880918624235 \t (loss)= 0.04600816251298013 \t (accuracy)= 89.50917946796552 % \t time= 24547.277036190033\n",
      "Test==: loss =  1.3178948605046636 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 96 \t lr= 0.021204880918624235 \t (loss)= 0.04617154547275153 \t (accuracy)= 89.50917946796552 % \t time= 24808.543704271317\n",
      "Test==: loss =  1.3267892408523179 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 97 \t lr= 0.021204880918624235 \t (loss)= 0.04632140258035187 \t (accuracy)= 89.3697181632738 % \t time= 25069.396971464157\n",
      "Test==: loss =  1.3246585564339162 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 98 \t lr= 0.021204880918624235 \t (loss)= 0.0460239909682413 \t (accuracy)= 89.49044585987261 % \t time= 25328.56502509117\n",
      "Test==: loss =  1.3287564322587873 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 99 \t lr= 0.021204880918624235 \t (loss)= 0.04601682445811778 \t (accuracy)= 89.59868448440947 % \t time= 25589.31969332695\n",
      "Test==: loss =  1.351282144014858 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 100 \t lr= 0.019277164471476576 \t (loss)= 0.04755832850069756 \t (accuracy)= 89.16781149827234 % \t time= 25847.324665308\n",
      "Test==: loss =  1.3651506162886815 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 101 \t lr= 0.019277164471476576 \t (loss)= 0.047383022234636744 \t (accuracy)= 89.28853919487115 % \t time= 26105.73557472229\n",
      "Test==: loss =  1.360999685792016 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 102 \t lr= 0.019277164471476576 \t (loss)= 0.04715582323435756 \t (accuracy)= 89.27813163481953 % \t time= 26363.412274837494\n",
      "Test==: loss =  1.358407689517369 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 103 \t lr= 0.019277164471476576 \t (loss)= 0.04698580624679433 \t (accuracy)= 89.27396861079887 % \t time= 26619.42645430565\n",
      "Test==: loss =  1.341430799856223 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 104 \t lr= 0.019277164471476576 \t (loss)= 0.04692098478345551 \t (accuracy)= 89.40510386744933 % \t time= 26875.281631946564\n",
      "Test==: loss =  1.3208370049482876 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 105 \t lr= 0.019277164471476576 \t (loss)= 0.04664255803077529 \t (accuracy)= 89.42800049956288 % \t time= 27129.022272586823\n",
      "Test==: loss =  1.3055743792527925 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 106 \t lr= 0.019277164471476576 \t (loss)= 0.04626104318489539 \t (accuracy)= 89.55497273219267 % \t time= 27387.843338489532\n",
      "Test==: loss =  1.3036820430631533 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 107 \t lr= 0.019277164471476576 \t (loss)= 0.0461717046659679 \t (accuracy)= 89.46754922775905 % \t time= 27643.16238427162\n",
      "Test==: loss =  1.3194838552860368 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 108 \t lr= 0.019277164471476576 \t (loss)= 0.0461897137842932 \t (accuracy)= 89.52583156404812 % \t time= 27900.00125479698\n",
      "Test==: loss =  1.3063740226417926 \t accuracy= 4.964406144623455 %\n",
      "\n",
      "Train::: epoch= 109 \t lr= 0.019277164471476576 \t (loss)= 0.046256410115988654 \t (accuracy)= 89.5070979559552 % \t time= 28154.847723722458\n",
      "Test==: loss =  1.293299090837588 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 110 \t lr= 0.017524694974069614 \t (loss)= 0.04750074054007255 \t (accuracy)= 89.14075184213813 % \t time= 28412.598220348358\n",
      "Test==: loss =  1.2849478878582972 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 111 \t lr= 0.017524694974069614 \t (loss)= 0.04748475885870693 \t (accuracy)= 89.12618125806586 % \t time= 28671.85370516777\n",
      "Test==: loss =  1.300701638206371 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 112 \t lr= 0.017524694974069614 \t (loss)= 0.04730440801807334 \t (accuracy)= 89.22817534657175 % \t time= 28929.78273677826\n",
      "Test==: loss =  1.2928683663516782 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 113 \t lr= 0.017524694974069614 \t (loss)= 0.047404728125383225 \t (accuracy)= 89.17821905832398 % \t time= 29188.143169641495\n",
      "Test==: loss =  1.3241553239033392 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 114 \t lr= 0.017524694974069614 \t (loss)= 0.047331050140528054 \t (accuracy)= 89.16156696224137 % \t time= 29445.46764063835\n",
      "Test==: loss =  1.351070811438074 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 115 \t lr= 0.017524694974069614 \t (loss)= 0.04736446855916412 \t (accuracy)= 89.15948545023105 % \t time= 29703.105666160583\n",
      "Test==: loss =  1.3393936629510648 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 116 \t lr= 0.017524694974069614 \t (loss)= 0.04742046095031067 \t (accuracy)= 89.11577369801424 % \t time= 29962.69849729538\n",
      "Test==: loss =  1.3708495328931507 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 117 \t lr= 0.017524694974069614 \t (loss)= 0.04742405785615737 \t (accuracy)= 89.171974522293 % \t time= 30220.92889404297\n",
      "Test==: loss =  1.375775952672334 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 118 \t lr= 0.017524694974069614 \t (loss)= 0.047775718113014135 \t (accuracy)= 89.0262686815703 % \t time= 30478.372682094574\n",
      "Test==: loss =  1.3887698184304533 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 119 \t lr= 0.017524694974069614 \t (loss)= 0.04804045995863732 \t (accuracy)= 89.05332833770451 % \t time= 30738.862066030502\n",
      "Test==: loss =  1.3396059849512456 \t accuracy= 5.114275009366804 %\n",
      "\n",
      "Train::: epoch= 120 \t lr= 0.01593154088551783 \t (loss)= 0.05013327746099399 \t (accuracy)= 88.52254277507181 % \t time= 30998.21009516716\n",
      "Test==: loss =  1.3957622595863295 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 121 \t lr= 0.01593154088551783 \t (loss)= 0.04960725252448157 \t (accuracy)= 88.61829232754673 % \t time= 31256.37810277939\n",
      "Test==: loss =  1.402557876312981 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 122 \t lr= 0.01593154088551783 \t (loss)= 0.049360259022285614 \t (accuracy)= 88.63910744764996 % \t time= 31512.237147808075\n",
      "Test==: loss =  1.3977293440009193 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 123 \t lr= 0.01593154088551783 \t (loss)= 0.0488742003760708 \t (accuracy)= 88.78481328837267 % \t time= 31769.11353778839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test==: loss =  1.3874947593185591 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 124 \t lr= 0.01593154088551783 \t (loss)= 0.048548878792425296 \t (accuracy)= 88.82228050455852 % \t time= 32026.012152910233\n",
      "Test==: loss =  1.3939001117530678 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 125 \t lr= 0.01593154088551783 \t (loss)= 0.04910427812771777 \t (accuracy)= 88.74734607218684 % \t time= 32283.07087945938\n",
      "Test==: loss =  1.3620157643379587 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 126 \t lr= 0.01593154088551783 \t (loss)= 0.04921397689949556 \t (accuracy)= 88.67033012780485 % \t time= 32543.19270515442\n",
      "Test==: loss =  1.366653224995078 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 127 \t lr= 0.01593154088551783 \t (loss)= 0.04944863724598198 \t (accuracy)= 88.72861246409391 % \t time= 32799.48238158226\n",
      "Test==: loss =  1.3162513921844692 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 128 \t lr= 0.01593154088551783 \t (loss)= 0.0500941773204134 \t (accuracy)= 88.55376545522667 % \t time= 33055.50345993042\n",
      "Test==: loss =  1.246207265172252 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 129 \t lr= 0.01593154088551783 \t (loss)= 0.05018785248694869 \t (accuracy)= 88.54335789517506 % \t time= 33312.86649942398\n",
      "Test==: loss =  1.1921635945885694 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 130 \t lr= 0.01448321898683439 \t (loss)= 0.05230427479772583 \t (accuracy)= 88.1457891012031 % \t time= 33572.181898117065\n",
      "Test==: loss =  1.157906136079529 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 131 \t lr= 0.01448321898683439 \t (loss)= 0.05200391686964644 \t (accuracy)= 88.17493026934766 % \t time= 33830.60310840607\n",
      "Test==: loss =  1.1382741743121927 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 132 \t lr= 0.01448321898683439 \t (loss)= 0.05179446347419837 \t (accuracy)= 88.34561425419425 % \t time= 34084.8562040329\n",
      "Test==: loss =  1.0934096259321335 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 133 \t lr= 0.01448321898683439 \t (loss)= 0.05177760572120814 \t (accuracy)= 88.34561425419425 % \t time= 34338.08427071571\n",
      "Test==: loss =  1.0859058559426642 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 134 \t lr= 0.01448321898683439 \t (loss)= 0.05194591194791212 \t (accuracy)= 88.32271762208069 % \t time= 34596.312173604965\n",
      "Test==: loss =  1.1217400246724352 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 135 \t lr= 0.01448321898683439 \t (loss)= 0.05212418116664434 \t (accuracy)= 88.24778318970901 % \t time= 34854.64376974106\n",
      "Test==: loss =  1.137712015492574 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 136 \t lr= 0.01448321898683439 \t (loss)= 0.05226398108664641 \t (accuracy)= 88.19782690146121 % \t time= 35112.53815865517\n",
      "Test==: loss =  1.158910792939764 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 137 \t lr= 0.01448321898683439 \t (loss)= 0.052257037267370056 \t (accuracy)= 88.20407143749219 % \t time= 35373.69513773918\n",
      "Test==: loss =  1.174582205675142 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 138 \t lr= 0.01448321898683439 \t (loss)= 0.05197942786411147 \t (accuracy)= 88.28525040589484 % \t time= 35634.58159041405\n",
      "Test==: loss =  1.1853637024238297 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 139 \t lr= 0.01448321898683439 \t (loss)= 0.05206410265060868 \t (accuracy)= 88.17493026934766 % \t time= 35894.15225958824\n",
      "Test==: loss =  1.1934440238383188 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 140 \t lr= 0.01316656271530399 \t (loss)= 0.05382374403963483 \t (accuracy)= 87.85437741975771 % \t time= 36154.110292196274\n",
      "Test==: loss =  1.1797706528514529 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 141 \t lr= 0.01316656271530399 \t (loss)= 0.05339210519918001 \t (accuracy)= 87.8793555638816 % \t time= 36415.31464266777\n",
      "Test==: loss =  1.2265380926097966 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 142 \t lr= 0.01316656271530399 \t (loss)= 0.05285386210019324 \t (accuracy)= 88.06461013280047 % \t time= 36676.27697110176\n",
      "Test==: loss =  1.2366059503923783 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 143 \t lr= 0.01316656271530399 \t (loss)= 0.05270909474327617 \t (accuracy)= 87.99383872444943 % \t time= 36936.463019132614\n",
      "Test==: loss =  1.2276495921687245 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 144 \t lr= 0.01316656271530399 \t (loss)= 0.05252765201562053 \t (accuracy)= 88.12289246908954 % \t time= 37198.617243766785\n",
      "Test==: loss =  1.225002190931984 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 145 \t lr= 0.01316656271530399 \t (loss)= 0.05238676538928019 \t (accuracy)= 88.17909329336831 % \t time= 37457.746599435806\n",
      "Test==: loss =  1.2308577014096258 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 146 \t lr= 0.01316656271530399 \t (loss)= 0.05256495357946397 \t (accuracy)= 88.1187294450689 % \t time= 37718.9570710659\n",
      "Test==: loss =  1.239662808081242 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 147 \t lr= 0.01316656271530399 \t (loss)= 0.052884618470126044 \t (accuracy)= 88.08334374089338 % \t time= 37979.76484155655\n",
      "Test==: loss =  1.2433642351972618 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 148 \t lr= 0.01316656271530399 \t (loss)= 0.052977041187791674 \t (accuracy)= 88.02506140460432 % \t time= 38242.069638967514\n",
      "Test==: loss =  1.2470513806375796 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 149 \t lr= 0.01316656271530399 \t (loss)= 0.052992175116091784 \t (accuracy)= 87.89392614795388 % \t time= 38504.01408672333\n",
      "Test==: loss =  1.2571171410597797 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 150 \t lr= 0.011969602468458171 \t (loss)= 0.05513960438586932 \t (accuracy)= 87.46513467382707 % \t time= 38763.77146720886\n",
      "Test==: loss =  1.245039974456433 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 151 \t lr= 0.011969602468458171 \t (loss)= 0.055225997201918904 \t (accuracy)= 87.5192539860955 % \t time= 39021.61261796951\n",
      "Test==: loss =  1.2294542693456247 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 152 \t lr= 0.011969602468458171 \t (loss)= 0.05533611936299974 \t (accuracy)= 87.53174305815745 % \t time= 39278.04331064224\n",
      "Test==: loss =  1.1392391652217082 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 153 \t lr= 0.011969602468458171 \t (loss)= 0.05578516641348133 \t (accuracy)= 87.41101536155864 % \t time= 39534.123311042786\n",
      "Test==: loss =  1.1045541484087051 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 154 \t lr= 0.011969602468458171 \t (loss)= 0.05508342329123554 \t (accuracy)= 87.53798759418842 % \t time= 39788.9849023819\n",
      "Test==: loss =  1.1101082564915146 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 155 \t lr= 0.011969602468458171 \t (loss)= 0.05503441809587115 \t (accuracy)= 87.63998168269431 % \t time= 40042.49974322319\n",
      "Test==: loss =  1.126366066918917 \t accuracy= 4.945672536530536 %\n",
      "\n",
      "Train::: epoch= 156 \t lr= 0.011969602468458171 \t (loss)= 0.05499470412363073 \t (accuracy)= 87.57337329836393 % \t time= 40293.710443496704\n",
      "Test==: loss =  1.1603596418917597 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 157 \t lr= 0.011969602468458171 \t (loss)= 0.054942064095732074 \t (accuracy)= 87.554639690271 % \t time= 40547.32315611839\n",
      "Test==: loss =  1.1612436771936556 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 158 \t lr= 0.011969602468458171 \t (loss)= 0.0551761916399205 \t (accuracy)= 87.5192539860955 % \t time= 40801.19769072533\n",
      "Test==: loss =  1.1654641607475233 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 159 \t lr= 0.011969602468458171 \t (loss)= 0.05527062078984249 \t (accuracy)= 87.58169934640523 % \t time= 41058.97063612938\n",
      "Test==: loss =  1.1391464921880745 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 160 \t lr= 0.010881456789507428 \t (loss)= 0.056740694666444096 \t (accuracy)= 87.15290787227842 % \t time= 41316.61822128296\n",
      "Test==: loss =  1.1088882366473216 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 161 \t lr= 0.010881456789507428 \t (loss)= 0.056093355147584775 \t (accuracy)= 87.38811872944507 % \t time= 41570.39127159119\n",
      "Test==: loss =  1.1319748928784574 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 162 \t lr= 0.010881456789507428 \t (loss)= 0.05644405771604033 \t (accuracy)= 87.24241288872237 % \t time= 41826.06862640381\n",
      "Test==: loss =  1.1448597306229962 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 163 \t lr= 0.010881456789507428 \t (loss)= 0.056679191944476175 \t (accuracy)= 87.29236917697015 % \t time= 42080.46569466591\n",
      "Test==: loss =  1.1271874290664283 \t accuracy= 5.076807793180967 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train::: epoch= 164 \t lr= 0.010881456789507428 \t (loss)= 0.05629158294260804 \t (accuracy)= 87.30485824903211 % \t time= 42338.51597738266\n",
      "Test==: loss =  1.1089523091798268 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 165 \t lr= 0.010881456789507428 \t (loss)= 0.056003795613115664 \t (accuracy)= 87.30902127305275 % \t time= 42591.95710372925\n",
      "Test==: loss =  1.1047459091841842 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 166 \t lr= 0.010881456789507428 \t (loss)= 0.05565887520914489 \t (accuracy)= 87.36105907331086 % \t time= 42848.29813885689\n",
      "Test==: loss =  1.1166502454288032 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 167 \t lr= 0.010881456789507428 \t (loss)= 0.05612724027867118 \t (accuracy)= 87.31942883310437 % \t time= 43101.96578454971\n",
      "Test==: loss =  1.1067007535101328 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 168 \t lr= 0.010881456789507428 \t (loss)= 0.056535927425873926 \t (accuracy)= 87.2965322009908 % \t time= 43359.58807039261\n",
      "Test==: loss =  1.0585420000273034 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 169 \t lr= 0.010881456789507428 \t (loss)= 0.05662034260344742 \t (accuracy)= 87.1591524083094 % \t time= 43613.30608177185\n",
      "Test==: loss =  1.0582590578171363 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 170 \t lr= 0.009892233445006752 \t (loss)= 0.05833473490699132 \t (accuracy)= 86.73660547021356 % \t time= 43866.891570329666\n",
      "Test==: loss =  1.0544281656478847 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 171 \t lr= 0.009892233445006752 \t (loss)= 0.057505648270282254 \t (accuracy)= 87.07589192789642 % \t time= 44122.75400519371\n",
      "Test==: loss =  1.058373818619424 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 172 \t lr= 0.009892233445006752 \t (loss)= 0.057254532916976734 \t (accuracy)= 87.14041880021648 % \t time= 44378.292535066605\n",
      "Test==: loss =  1.064713022123941 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 173 \t lr= 0.009892233445006752 \t (loss)= 0.05722733881245434 \t (accuracy)= 87.1945381124849 % \t time= 44633.92469191551\n",
      "Test==: loss =  1.0987482065301324 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 174 \t lr= 0.009892233445006752 \t (loss)= 0.05689974044470456 \t (accuracy)= 87.1508263602681 % \t time= 44889.65938806534\n",
      "Test==: loss =  1.0881543643075695 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 175 \t lr= 0.009892233445006752 \t (loss)= 0.05660785747639988 \t (accuracy)= 87.16955996836103 % \t time= 45145.007650613785\n",
      "Test==: loss =  1.0880584267879372 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 176 \t lr= 0.009892233445006752 \t (loss)= 0.05656078879889975 \t (accuracy)= 87.19870113650556 % \t time= 45400.14794373512\n",
      "Test==: loss =  1.0916689591106514 \t accuracy= 5.001873360809292 %\n",
      "\n",
      "Train::: epoch= 177 \t lr= 0.009892233445006752 \t (loss)= 0.05653599417224473 \t (accuracy)= 87.13833728820616 % \t time= 45654.76212477684\n",
      "Test==: loss =  1.1030476515022134 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 178 \t lr= 0.009892233445006752 \t (loss)= 0.056575037982361284 \t (accuracy)= 87.21743474459848 % \t time= 45911.59201359749\n",
      "Test==: loss =  1.1069861464519017 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 179 \t lr= 0.009892233445006752 \t (loss)= 0.05661270938442578 \t (accuracy)= 87.17996752841263 % \t time= 46167.52126765251\n",
      "Test==: loss =  1.1055669948923061 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 180 \t lr= 0.008992939495460683 \t (loss)= 0.05898258311663418 \t (accuracy)= 86.71787186212065 % \t time= 46423.446967840195\n",
      "Test==: loss =  1.0827960455677912 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 181 \t lr= 0.008992939495460683 \t (loss)= 0.05887704182690139 \t (accuracy)= 86.73244244619292 % \t time= 46679.31018304825\n",
      "Test==: loss =  1.083506908648992 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 182 \t lr= 0.008992939495460683 \t (loss)= 0.059727343236818414 \t (accuracy)= 86.66999708588318 % \t time= 46933.08947920799\n",
      "Test==: loss =  1.0723162848652878 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 183 \t lr= 0.008992939495460683 \t (loss)= 0.060344602907527536 \t (accuracy)= 86.53053578119145 % \t time= 47187.2712430954\n",
      "Test==: loss =  1.077390040677614 \t accuracy= 4.983139752716373 %\n",
      "\n",
      "Train::: epoch= 184 \t lr= 0.008992939495460683 \t (loss)= 0.06059928059473881 \t (accuracy)= 86.51804670912952 % \t time= 47443.32477545738\n",
      "Test==: loss =  1.085276247946575 \t accuracy= 5.039340576995129 %\n",
      "\n",
      "Train::: epoch= 185 \t lr= 0.008992939495460683 \t (loss)= 0.06064576997064494 \t (accuracy)= 86.5346988052121 % \t time= 47699.62613654137\n",
      "Test==: loss =  1.0568874828299288 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 186 \t lr= 0.008992939495460683 \t (loss)= 0.060863820958065196 \t (accuracy)= 86.4909870529953 % \t time= 47957.988530397415\n",
      "Test==: loss =  1.0502783928637938 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 187 \t lr= 0.008992939495460683 \t (loss)= 0.06143989728724962 \t (accuracy)= 86.44103076474752 % \t time= 48217.450941085815\n",
      "Test==: loss =  1.0170454482844584 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 188 \t lr= 0.008992939495460683 \t (loss)= 0.06171957705527795 \t (accuracy)= 86.37858540443779 % \t time= 48476.413445711136\n",
      "Test==: loss =  0.9834433336159482 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 189 \t lr= 0.008992939495460683 \t (loss)= 0.06195034008686507 \t (accuracy)= 86.33903667624162 % \t time= 48734.47617459297\n",
      "Test==: loss =  0.9743314807367769 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 190 \t lr= 0.008175399541327894 \t (loss)= 0.06415288860983875 \t (accuracy)= 85.86237042587736 % \t time= 48996.50254750252\n",
      "Test==: loss =  0.9644620876374677 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 191 \t lr= 0.008175399541327894 \t (loss)= 0.06346551295546952 \t (accuracy)= 86.02264685067233 % \t time= 49254.61222434044\n",
      "Test==: loss =  0.9654009606667597 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 192 \t lr= 0.008175399541327894 \t (loss)= 0.06351443132819438 \t (accuracy)= 86.02056533866201 % \t time= 49514.23119497299\n",
      "Test==: loss =  0.9747268272936489 \t accuracy= 5.095541401273886 %\n",
      "\n",
      "Train::: epoch= 193 \t lr= 0.008175399541327894 \t (loss)= 0.06370585376347675 \t (accuracy)= 85.89775613005287 % \t time= 49775.635350465775\n",
      "Test==: loss =  0.9663815737614219 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 194 \t lr= 0.008175399541327894 \t (loss)= 0.06354764226321825 \t (accuracy)= 85.91024520211482 % \t time= 50037.95665335655\n",
      "Test==: loss =  0.9828342558526937 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 195 \t lr= 0.008175399541327894 \t (loss)= 0.06388126495700619 \t (accuracy)= 85.88943008201157 % \t time= 50298.273126363754\n",
      "Test==: loss =  0.9748513073873899 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 196 \t lr= 0.008175399541327894 \t (loss)= 0.0638298543411347 \t (accuracy)= 85.76245784938179 % \t time= 50558.34700632095\n",
      "Test==: loss =  0.9959987400945972 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 197 \t lr= 0.008175399541327894 \t (loss)= 0.06418855136885654 \t (accuracy)= 85.77494692144374 % \t time= 50817.968162059784\n",
      "Test==: loss =  1.0261359353431447 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 198 \t lr= 0.008175399541327894 \t (loss)= 0.06439415731933182 \t (accuracy)= 85.6604637608759 % \t time= 51075.53514838219\n",
      "Test==: loss =  1.0385966530450566 \t accuracy= 5.058074185088048 %\n",
      "\n",
      "Train::: epoch= 199 \t lr= 0.008175399541327894 \t (loss)= 0.06460310101944944 \t (accuracy)= 85.67295283293784 % \t time= 51335.48709988594\n",
      "Test==: loss =  1.0370667427242286 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 200 \t lr= 0.0074321814012071755 \t (loss)= 0.06767289053154803 \t (accuracy)= 85.04641771783024 % \t time= 51595.56422472\n",
      "Test==: loss =  0.9976110373075237 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 201 \t lr= 0.0074321814012071755 \t (loss)= 0.06774717588901015 \t (accuracy)= 85.08388493401607 % \t time= 51853.261645793915\n",
      "Test==: loss =  0.9795214688634876 \t accuracy= 5.02060696890221 %\n",
      "\n",
      "Train::: epoch= 202 \t lr= 0.0074321814012071755 \t (loss)= 0.06717734809258753 \t (accuracy)= 85.30660671912077 % \t time= 52112.85952997208\n",
      "Test==: loss =  0.9771307499540299 \t accuracy= 5.076807793180967 %\n",
      "\n",
      "Train::: epoch= 203 \t lr= 0.0074321814012071755 \t (loss)= 0.06708266992885667 \t (accuracy)= 85.29411764705883 % \t time= 52369.54773378372\n",
      "Test==: loss =  0.9852460867477907 \t accuracy= 5.076807793180967 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train::: epoch= 204 \t lr= 0.0074321814012071755 \t (loss)= 0.06722536387524683 \t (accuracy)= 85.32534032721368 % \t time= 52605.07617545128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1ae40e812948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# evaluate on test set to monitor the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0macc_tst_plt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tst_plt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_on_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# saving test parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-ad49f6f6735f>\u001b[0m in \u001b[0;36meval_on_test_set\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# sending to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0minpute_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minpute_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "# shuff_index=torch.LongTensor(485224).random_(0,485224)\n",
    "# train_data_2=train_data_1[:,shuff_index]\n",
    "# train_labels_2=train_labels_1[:,shuff_index]\n",
    "\n",
    "accu_plt=[]\n",
    "loss_plt=[]\n",
    "test_loss_plt=[]\n",
    "accuracy_test_plt=[]\n",
    "confusion_mtx_parameters=[]\n",
    "\n",
    "for epoch in range(1,1000):\n",
    "    # to activate dropout during training \n",
    "    lstm_net.train()\n",
    "    # divide the learning rate by 3 except after the first epoch\n",
    "    if epoch % 10==0:\n",
    "        my_lr = my_lr / 1.1\n",
    "\n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "    lstm_optimizer=torch.optim.SGD( lstm_net.parameters() , lr=my_lr )\n",
    "    # set the initial h and c to be the zero vector\n",
    "\n",
    "        \n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "    num_matches=0\n",
    "    \n",
    "    # loop across batch of words\n",
    "    for i in range(0,num_train_words):\n",
    "      # initilize the hidden state every word as the words ara independent \n",
    "    \n",
    "        h = torch.zeros(1,batch_of_words,  hidden_size).cuda()\n",
    "        c = torch.zeros(1,batch_of_words,  hidden_size).cuda()\n",
    "        h=h.to(device)\n",
    "        c=c.to(device)\n",
    "    \n",
    "        word_length= len(train_data_1 [i])\n",
    "    # Set the gradients to zeros\n",
    "        lstm_optimizer.zero_grad()\n",
    "\n",
    "        minibatch_words  =  train_data_1[i ]\n",
    "        minibatch_labels =  train_labels_1[ i]\n",
    "        # sending to GPU\n",
    "        minibatch_words=minibatch_words.to(device)\n",
    "        minibatch_labels=minibatch_labels.to(device)\n",
    "\n",
    "\n",
    "        # Detach to prevent from backpropagating all the way to the beginning\n",
    "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
    "        h=h.detach()\n",
    "        c=c.detach()\n",
    "        h=h.requires_grad_()\n",
    "        c=c.requires_grad_()\n",
    "\n",
    "        # forward pass\n",
    "        scores_char, h, c = lstm_net(minibatch_words.view(word_length,1), h, c)\n",
    "\n",
    "        # reshape before calculating the loss for easier slicing of mini batch of words\n",
    "        scores_char = scores_char.view(  word_length*batch_of_words , vocab_size)\n",
    "        minibatch_labels = minibatch_labels.contiguous()\n",
    "        minibatch_labels = minibatch_labels.view(word_length*batch_of_words )\n",
    "        # calculating the loss of batch of character sthat constrcut a words\n",
    "        loss_char= criterion(scores_char, minibatch_labels)\n",
    "\n",
    "        #===============================================\n",
    "\n",
    "        # summation of both lossses to \n",
    "        combined_loss=loss_char\n",
    "\n",
    "\n",
    "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
    "        combined_loss.backward()\n",
    "\n",
    "        # update the wights \n",
    "        lstm_optimizer.step()\n",
    "\n",
    "\n",
    "        # update the running loss  \n",
    "        running_loss += combined_loss.detach().item()\n",
    "        num_batches += 1\n",
    "        num_matches += get_error(scores_char, minibatch_labels)\n",
    "        \n",
    "        # end of iteration \n",
    "        \n",
    "    # compute for full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    loss_plt.append(total_loss)\n",
    "    accuracy= (num_matches/num_train_words)*100\n",
    "    accu_plt.append(accuracy)\n",
    "    # Compute the time \n",
    "    elapsed = time.time()-start\n",
    "    \n",
    "    print('')\n",
    "    print('Train:::', 'epoch=',epoch,'\\t lr=', my_lr, '\\t (loss)=',(total_loss),'\\t (accuracy)=' , (accuracy),'%','\\t time=', elapsed)\n",
    "    \n",
    "    # evaluate on test set to monitor the loss \n",
    "    acc_tst_plt, loss_tst_plt, confusion_param=eval_on_test_set()\n",
    "    \n",
    "    # saving test parameters  \n",
    "    test_loss_plt.append(loss_tst_plt)\n",
    "    accuracy_test_plt.append(acc_tst_plt)\n",
    "    confusion_mtx_parameters.append(confusion_param)\n",
    "    #### Saving model parameters every epoch \n",
    "    save_model_parameters() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []], [[1.0], [1.0], [1.0], [0.0], []]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_mtx_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('lstm_single_char_50_mutation_bid_drop.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andriashfahani/miniconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Recurrent_Layer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(lstm_net, 'this_morning_w_do.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint['test_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.save(lstm_net,'single_mistake_model_lstm_drop_out_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('lstm_single_char_50_mutation_bid_drop_02.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008481162786483764, 0.009953457117080688, 0.008462512493133545, 0.008568865060806275, 0.008872705698013305, 0.009778851270675659, 0.009399718046188355, 0.009138405323028564, 0.008280891180038451, 0.00938764214515686, 0.009248465299606323, 0.010755127668380738, 0.009009695053100586, 0.008971762657165528, 0.01076977252960205, 0.01007135510444641, 0.010158282518386842, 0.008264505863189697, 0.008282959461212158, 0.01121429204940796, 0.008798831701278686, 0.009055852890014648, 0.010330718755722047, 0.007766813039779663, 0.009448951482772827, 0.009692203998565675, 0.00912320613861084, 0.009875631332397461, 0.008551460504531861, 0.01096159815788269, 0.009085208177566528, 0.009600162506103516, 0.00832710862159729, 0.010008686780929565, 0.009891873598098755, 0.010521680116653442, 0.010294747352600098, 0.009758317470550537, 0.010009801387786866, 0.008804881572723388, 0.008309823274612427, 0.009526288509368897, 0.008488410711288452, 0.008953988552093506, 0.009343469142913818, 0.00920448899269104, 0.010769516229629517, 0.007997560501098632, 0.010012930631637574, 0.008238482475280761, 0.007914996147155762, 0.008441448211669922, 0.008660966157913208, 0.008735442161560058, 0.01002773642539978, 0.007890093326568603, 0.0065487980842590336, 0.009454089403152465, 0.011431741714477538, 0.007453322410583496, 0.009435546398162842, 0.007637321949005127, 0.008381032943725586, 0.009216135740280152]\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint[])\n",
    "#  'incorrect_to_correct':confusion_mtx_parameters[0],  'correct_to_correct':confusion_mtx_parameters[2],\n",
    "# #                 'correct_to_incorrect':confusion_mtx_parameters[1],'regenerate':confusion_mtx_parameters[3]\n",
    "  \n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
