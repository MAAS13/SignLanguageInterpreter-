{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import os, sys  \n",
    "import string   \n",
    "import math\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_num_param(net):\n",
    "    nb_param = 0\n",
    "    for param in net.parameters():\n",
    "        nb_param += param.numel()\n",
    "    print('There are {} ({:.2f} million) parameters in this neural network'.format(\n",
    "        nb_param, nb_param/1e6)\n",
    "         )\n",
    "\n",
    "\n",
    "def get_error( scores , labels ):\n",
    "    \n",
    "    scores = torch.transpose(scores, 0, 1)  ### num of words, seq_lenght if each word, 26\n",
    "    \n",
    "    bs=scores.size(0)\n",
    "    \n",
    "    predicted_labels = scores.argmax(dim=2)[0]\n",
    "    \n",
    "    indicator = torch.all(torch.eq(predicted_labels, labels))\n",
    "\n",
    "    num_matches=indicator.sum()\n",
    "    \n",
    "    return 1-num_matches.float()/bs    \n",
    "\n",
    "\n",
    "def csv2images(fileStr):\n",
    "    dataStr = csv.reader(open(fileStr), delimiter='\\n', quotechar='|')\n",
    "    data = []\n",
    "    next(dataStr)\n",
    "    for row in dataStr:\n",
    "        eachRow = ','.join(row);\n",
    "        rowArr = list(map(int, eachRow.split(',')));\n",
    "        data.append(rowArr)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_images = csv2images('sign_mnist_train.csv')\n",
    "test_images = csv2images('sign_mnist_test.csv')\n",
    "\n",
    "print(\"loading data...\")\n",
    "trainWordstrainImages = torch.load('trainWordstrainImages.pt')\n",
    "testWordstestImages = torch.load('testWordstestImages.pt')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = list(string.ascii_lowercase)\n",
    "\n",
    "trainWordstrainImages_data = []   #### this is the data we will use for training CSLTM\n",
    "trainWordstrainImages_labels = []\n",
    "\n",
    "testWordstestImages_data = []  \n",
    "testWordstestImages_labels = []\n",
    "    \n",
    "def get_data():\n",
    "\n",
    "    for wim in trainWordstrainImages[:40000]:\n",
    "\n",
    "        word_imgs = torch.tensor( [ train_images[i][1:] for i in wim[1] ] )  ###fetch image data in sequence\n",
    "        word_imgs = word_imgs.reshape(word_imgs.shape[0], 28, 28).float()  ### reshape to 28 x 28 images in sequence\n",
    "        word_imgs /= 255            #### make float!!\n",
    "\n",
    "        img_labels = [ train_images[i][0] for i in wim[1] ] \n",
    "\n",
    "        trainWordstrainImages_data.append(word_imgs)\n",
    "        trainWordstrainImages_labels.append(torch.tensor(img_labels))\n",
    "        \n",
    "    \n",
    "    \n",
    "    for wim in testWordstestImages[:4000]:\n",
    "\n",
    "        word_imgs = torch.tensor( [ test_images[i][1:] for i in wim[1] ] )  ###fetch image data in sequence\n",
    "        word_imgs = word_imgs.reshape(word_imgs.shape[0], 28, 28).float()  ### reshape to 28 x 28 images in sequence\n",
    "        word_imgs /= 255            #### make float!!\n",
    "\n",
    "        img_labels = [ test_images[i][0] for i in wim[1] ] \n",
    "\n",
    "        testWordstestImages_data.append(word_imgs)\n",
    "        testWordstestImages_labels.append(torch.tensor(img_labels))\n",
    "\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 4000\n",
      "torch.Size([8, 28, 28]) torch.Size([8])\n",
      "torch.Size([11, 28, 28]) torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "print(len(trainWordstrainImages_data), len(testWordstestImages_data))\n",
    "\n",
    "idx = 33\n",
    "print(trainWordstrainImages_data[idx].shape, trainWordstrainImages_labels[idx].shape)\n",
    "print(testWordstestImages_data[idx].shape, testWordstestImages_labels[idx].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, h_dim, classes, bi_dir=False):\n",
    "        \n",
    "        super(CLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_dim = h_dim\n",
    "        \n",
    "        # CL1:   28 x 28  -->    64 x 28 x 28 \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        # MP1: 64 x 28 x 28 -->    64 x 14 x 14\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # CL2:   64 x 14 x 14  -->    64 x 14 x 14 \n",
    "        self.conv2 = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
    "        \n",
    "        # MP2: 64 x 14 x 14  -->    64 x 7 x 7\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        # CL3:   64 x 7 x 7  -->    64 x 7 x 7 \n",
    "        self.conv3 = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
    "        \n",
    "        self.to_pad = 0\n",
    "        # MP3: 64 x 7 x 7  -->    64 x 4 x 4 or 64 x 3 x 3, depending on padding\n",
    "        self.pool3 = nn.MaxPool2d(2,2, padding=self.to_pad)\n",
    "        \n",
    "        if self.to_pad:\n",
    "            # LL1:   64 x 4 x 4 = 1024 -->  128 \n",
    "            self.linear1 = nn.Linear(1024, 128)\n",
    "        else:\n",
    "            # LL1:   64 x 3 x 3 = 576 -->  128 \n",
    "            self.linear1 = nn.Linear(576, 128)\n",
    "        \n",
    "        \n",
    "        #self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout1 = nn.Dropout(0.7)\n",
    "        \n",
    "        #self.dropout2 = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.7)\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm_in_dim = 128\n",
    "        self.lstm = nn.LSTM(self.lstm_in_dim, self.hidden_dim, bidirectional=bi_dir)\n",
    "\n",
    "        # linear\n",
    "        self.hidden2label1 = nn.Linear( self.hidden_dim*(1+int(bi_dir)), classes )\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, h_init, c_init):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "         \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.pool2(x)\n",
    " \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # MP3: 64 x 7 x 7  -->    64 x 4 x 4 or 64 x 3 x 3, depending on padding\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        if self.to_pad: x = x.view(-1, 1024)   ### reshape\n",
    "        else: x = x.view(-1, 576)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)     \n",
    "        \n",
    "        # Droput\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        cnn_x = F.relu(x) \n",
    "        \n",
    "        # LSTM\n",
    "        g_seq = cnn_x.unsqueeze(dim=1)\n",
    "        lstm_out, (h_final, c_final) = self.lstm(g_seq, (h_init, c_init))\n",
    "        \n",
    "        # Droput\n",
    "        lstm_out = self.dropout2(lstm_out)\n",
    "        \n",
    "        # linear\n",
    "        cnn_lstm_out = self.hidden2label1(lstm_out)  ###activtions are implicit\n",
    "\n",
    "        # output\n",
    "        scores = cnn_lstm_out\n",
    "\n",
    "        return scores, h_final, c_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 952218 (0.95 million) parameters in this neural network\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device= torch.device(\"cuda\")\n",
    "else:\n",
    "    device= torch.device(\"cpu\")\n",
    "\n",
    "classes = 26\n",
    "hidden_dim_of_lstm1 = 256\n",
    "\n",
    "bi_dir = True\n",
    "clstm = CLSTM(hidden_dim_of_lstm1, classes, bi_dir)\n",
    "num_lstm_layers = 1;\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    clstm = clstm.cuda()\n",
    "\n",
    "print(display_num_param(clstm))\n",
    "\n",
    "my_lr = 0.04\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(eval_net, typ=None):\n",
    "    \n",
    "    \n",
    "    test_data = testWordstestImages_data\n",
    "    test_labels = testWordstestImages_labels\n",
    "        \n",
    "        \n",
    "    num_words = len(test_data)\n",
    "    num_words = 2000\n",
    "    #print('num of test data: ', num_words, '\\n')\n",
    "\n",
    "    start=time.time()\n",
    "\n",
    "    #clear the loss for every epoch \n",
    "    total_loss = 0\n",
    "    running_loss = 0\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for wrd in range(num_words):\n",
    "        \n",
    "        input_tensor = test_data[wrd].unsqueeze(dim=1)\n",
    "        target_tensor= test_labels[wrd]\n",
    "        \n",
    "        if device.type == \"cuda\":\n",
    "            input_tensor = input_tensor.cuda()\n",
    "            target_tensor = target_tensor.cuda()\n",
    "        \n",
    "        #initial hidden states\n",
    "        h = torch.zeros((1+int(bi_dir))*num_lstm_layers, 1, hidden_dim_of_lstm1) ### if bi_dir=True, first dimension is 2 for bi-directional\n",
    "        c = torch.zeros((1+int(bi_dir))*num_lstm_layers, 1, hidden_dim_of_lstm1)\n",
    "\n",
    "        h = h.to(device)\n",
    "        c = c.to(device)\n",
    "\n",
    "        out, h, c = eval_net(input_tensor, h, c)\n",
    "        \n",
    "        running_error += get_error( out.detach() , target_tensor).item()\n",
    "        \n",
    "        out =   out.view(  len(input_tensor) , classes)\n",
    "        \n",
    "\n",
    "        running_loss += criterion(out, target_tensor).item()        \n",
    "        \n",
    "\n",
    "        num_batches += 1\n",
    "        \n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = time.time()-start\n",
    "   \n",
    "    print('\\n::::::::::::::::::::::::EVAL::::::::::::::::::::::::\\n ', '\\t exp(loss)=', math.exp(total_loss),'\\t (loss)=' , (total_loss), \n",
    "                                                                      '\\t error=', total_error*100 ,'percent')\n",
    "    print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of train data:  20000 \n",
      "\n",
      "TRAIN:::  epoch= 0 \t time= 121.95036435127258 \t lr= 0.04 \t exp(loss)= 1.9661237427904572 \t (loss)= 0.6760639611432598 \t error= 58.24 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 1 \t time= 243.31008505821228 \t lr= 0.04 \t exp(loss)= 1.3678195645864681 \t (loss)= 0.31321791326903986 \t error= 33.055 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 2 \t time= 365.16282296180725 \t lr= 0.04 \t exp(loss)= 1.094389691086841 \t (loss)= 0.09019684814774188 \t error= 15.620000000000001 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 3 \t time= 486.6857125759125 \t lr= 0.04 \t exp(loss)= 1.0428794451324424 \t (loss)= 0.04198558461379817 \t error= 9.17 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 4 \t time= 607.9333639144897 \t lr= 0.04 \t exp(loss)= 1.0228241251896713 \t (loss)= 0.022567551553735434 \t error= 5.36 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 5 \t time= 729.4032871723175 \t lr= 0.04 \t exp(loss)= 1.016567503790954 \t (loss)= 0.016431759939343923 \t error= 3.8350000000000004 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 6 \t time= 851.0047750473022 \t lr= 0.04 \t exp(loss)= 1.0113245997830922 \t (loss)= 0.011260956541732986 \t error= 2.795 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 7 \t time= 972.6337997913361 \t lr= 0.04 \t exp(loss)= 1.009451091695271 \t (loss)= 0.009406709548840065 \t error= 2.505 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 8 \t time= 1094.532734632492 \t lr= 0.04 \t exp(loss)= 1.0072026784388086 \t (loss)= 0.007176863036371368 \t error= 1.725 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 9 \t time= 1216.066087961197 \t lr= 0.03333333333333333 \t exp(loss)= 1.0051165121607784 \t (loss)= 0.0051034672896731635 \t error= 1.195 percent\n",
      "\n",
      "::::::::::::::::::::::::EVAL::::::::::::::::::::::::\n",
      "  \t exp(loss)= 1.2184512034100843 \t (loss)= 0.19758054683896573 \t error= 29.65 percent\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhayms93/miniconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type CLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TRAIN:::  epoch= 10 \t time= 1341.3444292545319 \t lr= 0.03333333333333333 \t exp(loss)= 1.0042982114420624 \t (loss)= 0.004289000515503158 \t error= 1.055 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 11 \t time= 1462.8457388877869 \t lr= 0.03333333333333333 \t exp(loss)= 1.0034169935099084 \t (loss)= 0.0034111688523583367 \t error= 0.89 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 12 \t time= 1583.9690253734589 \t lr= 0.03333333333333333 \t exp(loss)= 1.0028422092722744 \t (loss)= 0.00283817783249117 \t error= 0.75 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 13 \t time= 1704.8097331523895 \t lr= 0.03333333333333333 \t exp(loss)= 1.0027489541558205 \t (loss)= 0.0027451826914858396 \t error= 0.715 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 14 \t time= 1825.9969408512115 \t lr= 0.03333333333333333 \t exp(loss)= 1.002403970651429 \t (loss)= 0.0024010857365579868 \t error= 0.5700000000000001 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 15 \t time= 1947.2077431678772 \t lr= 0.03333333333333333 \t exp(loss)= 1.0021473389168387 \t (loss)= 0.0021450366798265734 \t error= 0.585 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 16 \t time= 2068.3611850738525 \t lr= 0.03333333333333333 \t exp(loss)= 1.0019496975449156 \t (loss)= 0.0019477993515255299 \t error= 0.545 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 17 \t time= 2189.5891695022583 \t lr= 0.03333333333333333 \t exp(loss)= 1.0018045036178072 \t (loss)= 0.0018028774571350794 \t error= 0.43 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 18 \t time= 2310.796894788742 \t lr= 0.03333333333333333 \t exp(loss)= 1.002039421614352 \t (loss)= 0.0020373448172554126 \t error= 0.52 percent\n",
      "\n",
      "\n",
      "TRAIN:::  epoch= 19 \t time= 2431.8816397190094 \t lr= 0.02777777777777778 \t exp(loss)= 1.0013683932194681 \t (loss)= 0.001367457822696408 \t error= 0.365 percent\n",
      "\n",
      "::::::::::::::::::::::::EVAL::::::::::::::::::::::::\n",
      "  \t exp(loss)= 1.2813280269530116 \t (loss)= 0.2478970611355846 \t error= 26.05 percent\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_words = len(trainWordstrainImages_data)\n",
    "num_words = 20000\n",
    "print('Num of train data: ', num_words, '\\n')\n",
    "\n",
    "#shuffled_indices = torch.randperm(num_words)\n",
    "\n",
    "start=time.time()\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    if (epoch+1) %10==0:\n",
    "        my_lr = my_lr / 1.2\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = torch.optim.SGD(clstm.parameters(), lr=my_lr)\n",
    "    \n",
    "    #clear the loss for every epoch \n",
    "    total_loss = 0\n",
    "    running_loss = 0\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for wrd in range(num_words):\n",
    "    #for wrd in shuffled_indices:\n",
    "        \n",
    "        input_tensor = trainWordstrainImages_data[wrd].unsqueeze(dim=1)\n",
    "        target_tensor= trainWordstrainImages_labels[wrd]\n",
    "        \n",
    "        if device.type == \"cuda\":\n",
    "            input_tensor = input_tensor.cuda()\n",
    "            target_tensor = target_tensor.cuda()\n",
    "        \n",
    "        #initial hidden states\n",
    "        h = torch.zeros((1+int(bi_dir))*num_lstm_layers, 1, hidden_dim_of_lstm1) ### if bi_dir=True, first dimension is 2 for bi-directional\n",
    "        c = torch.zeros((1+int(bi_dir))*num_lstm_layers, 1, hidden_dim_of_lstm1)\n",
    "\n",
    "\n",
    "        h = h.to(device)\n",
    "        c = c.to(device)\n",
    "\n",
    "        # set the gradient values to zero \n",
    "        optimizer.zero_grad()\n",
    "        encoder_outs=[]\n",
    "\n",
    "\n",
    "        out, h, c = clstm(input_tensor, h, c)\n",
    "        \n",
    "        running_error += get_error( out.detach() , target_tensor).item()\n",
    "        \n",
    "        out =   out.view(  len(input_tensor) , classes)\n",
    " \n",
    "        loss = criterion(out, target_tensor)\n",
    "       \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "        running_loss += loss.item()       \n",
    "        \n",
    "        \n",
    "        num_batches += 1\n",
    "        \n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = time.time()-start\n",
    "   \n",
    "    print('TRAIN::: ', 'epoch=',epoch, '\\t time=', elapsed,'\\t lr=', my_lr, '\\t exp(loss)=', math.exp(total_loss),'\\t (loss)=' , (total_loss), \n",
    "                                                                      '\\t error=', total_error*100 ,'percent')\n",
    "    \n",
    "    if (epoch+1)%10==0:\n",
    "        #eval_net = copy.deepcopy(clstm).eval()   ### this should be in evaluation mode\n",
    "        eval_net = clstm.eval()\n",
    "        evaluation(eval_net)\n",
    "        torch.save(clstm, 'CLSTM.pth')\n",
    "        clstm = clstm.train()\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
